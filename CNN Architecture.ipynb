{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad3ac1a4-b82c-4ec7-96c7-b0385e9f0113",
   "metadata": {},
   "source": [
    "Ans 1) Pooling, in the context of Convolutional Neural Networks (CNNs), serves several important purposes and provides various benefits:\n",
    "\n",
    "Purpose:\n",
    "\n",
    "Dimensionality reduction: The main advantage of pooling layers is that they help in reducing the spatial dimensions of the feature maps. This reduces the computational cost and also helps in avoiding overfitting by reducing the number of parameters in the model.\n",
    "\n",
    "Translation invariance: Pooling layers are also useful in achieving translation invariance in the feature maps. This means that the position of an object in the image does not affect the classification result, as the same features are detected regardless of the position of the object.\n",
    "\n",
    "Feature selection: Pooling layers can also help in selecting the most important features from the input, as max pooling selects the most salient features and average pooling preserves more information.\n",
    "Disadvantages of Pooling Layer:\n",
    "\n",
    "Information loss: One of the main disadvantages of pooling layers is that they discard some information from the input feature maps, which can be important for the final classification or regression task.\n",
    "\n",
    "Over-smoothing: Pooling layers can also cause over-smoothing of the feature maps, which can result in the loss of some fine-grained details that are important for the final classification or regression task.\n",
    "\n",
    "Hyperparameter tuning: Pooling layers also introduce hyperparameters such as the size of the pooling regions and the stride, which need to be tuned in order to achieve optimal performance. This can be time-consuming and requires some expertise in model building."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e265df-2cb6-4e92-9611-ece2a7428717",
   "metadata": {},
   "source": [
    "Ans 2) Max Pooling:\n",
    "\n",
    "In Max Pooling, for each local region (typically defined by a window or kernel size), the maximum value is selected and retained, while all other values are discarded. This means that the output of a max pooling operation for a given region contains only the most important or dominant feature present in that region.\n",
    "\n",
    "Max pooling is particularly effective at capturing the most prominent features within a region, promoting translation invariance, and providing robustness to small spatial shifts or distortions in the input.\n",
    "Average Pooling:\n",
    "\n",
    "In Average Pooling, for each local region, the average value of all the elements within that region is computed and retained. This means that the output of an average pooling operation for a given region contains the average intensity or activation level across that region.\n",
    "\n",
    "Average pooling provides a smoother down-sampling of the feature maps compared to max pooling. It tends to preserve more spatial information and can be useful in certain scenarios where maintaining finer spatial details is important.\n",
    "Here's a summary of the differences:\n",
    "\n",
    "Max Pooling: Selects the maximum value from each local region.\n",
    "\n",
    "Pros: Preserves dominant features, provides robustness to spatial shifts.\n",
    "Cons: May discard less significant features, can lead to loss of spatial information.\n",
    "Average Pooling: Computes the average value from each local region.\n",
    "\n",
    "Pros: Maintains spatial information better, smooths out noise in the data.\n",
    "Cons: Less effective in preserving dominant features, may not perform as well in tasks where precise spatial information is crucial.\n",
    "Both pooling techniques serve to reduce the spatial dimensions of the feature maps, thereby controlling the number of parameters and computational complexity of the network, while also promoting translation invariance and aiding in feature abstraction. The choice between max pooling and average pooling depends on the specific requirements of the task and the characteristics of the data being processed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9d09f07-c2a5-466e-8667-851e253b1d39",
   "metadata": {},
   "source": [
    "Ans 3) 1. What is Padding?\n",
    "\n",
    "In the context of CNNs, padding refers to the process of adding extra border pixels around the input images or feature maps before applying convolutional operations. These extra pixels are usually filled with zeros (zero-padding), although other padding strategies are also possible.\n",
    "\n",
    "2. Significance of Padding:\n",
    "\n",
    "a. Preservation of Spatial Dimensions:\n",
    "\n",
    "One significant aspect of padding is that it helps preserve the spatial dimensions of the input volume or feature maps. When we apply convolution operations without padding, the spatial dimensions of the output feature maps tend to decrease, which can lead to a loss of information at the edges of the image. Padding helps counteract this effect by ensuring that the spatial dimensions of the output feature maps match the dimensions of the input, or at least don't decrease as much.\n",
    "\n",
    "b. Control Over Output Size:\n",
    "\n",
    "Padding also provides control over the size of the output feature maps. By adjusting the amount of padding added to the input images, we can control the spatial dimensions of the output feature maps. This is particularly useful when designing CNN architectures, as it allows us to adjust the size of the feature maps according to the requirements of the task or the architecture of the network.\n",
    "\n",
    "c. Mitigating Border Effects:\n",
    "\n",
    "Padding helps mitigate border effects that can occur when applying convolution operations. Without padding, the pixels at the edges of the input images receive fewer convolutional operations compared to the pixels in the center, which can lead to the loss of important information at the edges. Padding ensures that all pixels in the input images are treated equally during convolution, thereby reducing border effects.\n",
    "\n",
    "d. Enhanced Learning of Edge Features:\n",
    "\n",
    "Padding can help enhance the learning of edge features in images. By adding extra pixels around the edges of the input images, we provide the convolutional filters with more context, which can help them learn to detect and recognize edges more effectively.\n",
    "\n",
    "e. Improved Performance and Robustness:\n",
    "\n",
    "Overall, padding contributes to improved performance and robustness of CNNs by preserving spatial information, controlling output size, mitigating border effects, and enhancing the learning of important features such as edges.\n",
    "\n",
    "In summary, padding is a crucial concept in CNNs that helps preserve spatial information, control output size, mitigate border effects, and enhance the learning of important features. It plays a significant role in the design and optimization of CNN architectures for various computer vision tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242abad4-ef0f-4894-ba57-58a63539bd1c",
   "metadata": {},
   "source": [
    "Ans 4 )1. Zero-padding (Same-padding):\n",
    "\n",
    "Definition: Zero-padding involves adding extra border pixels around the input images or feature maps, with these extra pixels being filled with zeros.\n",
    "\n",
    "Effect on Output Feature Map Size:\n",
    "\n",
    "With zero-padding, the output feature map size remains the same as the input size if the stride of the convolution operation is set to 1.\n",
    "This is because the padding ensures that the convolutional operation covers the entire input image without losing information at the edges.\n",
    "If the stride is greater than 1, the output feature map size will be reduced accordingly, but the relative spatial dimensions (width and height) between the input and output feature maps remain the same.\n",
    "Significance: Zero-padding is commonly used when we want to preserve the spatial dimensions of the input feature maps in the output. It helps in maintaining spatial information, controlling output size, and mitigating border effects during convolution operations.\n",
    "\n",
    "2. Valid-padding:\n",
    "\n",
    "Definition: Valid-padding (also known as no-padding) involves applying the convolutional operation without any additional padding to the input images or feature maps.\n",
    "\n",
    "Effect on Output Feature Map Size:\n",
    "\n",
    "With valid-padding, the output feature map size is reduced compared to the input size.\n",
    "The reduction in size depends on the size of the convolutional filter/kernel and the stride used in the convolution operation.\n",
    "Valid-padding results in no padding being applied to the input, so the edges of the input feature maps are not preserved in the output, leading to a smaller output size.\n",
    "Significance: Valid-padding is often used when we are less concerned about preserving the spatial dimensions of the input in the output and are more interested in reducing the size of the feature maps, which can help in reducing computational complexity and extracting more abstract features from the data.\n",
    "\n",
    "In Summary:\n",
    "\n",
    "Zero-padding (same-padding) preserves the spatial dimensions of the input feature maps in the output, while valid-padding reduces the output size by not applying any padding to the input.\n",
    "The choice between zero-padding and valid-padding depends on the specific requirements of the task and the desired properties of the CNN architecture, such as preserving spatial information, controlling output size, or reducing computational complexity."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81e171f7-405e-427a-a1e7-8844269a0cdd",
   "metadata": {},
   "source": [
    "  Exploring LENET\n",
    "Ans 1 ) Here's an overview of the LeNet-5 architecture:\n",
    "\n",
    "Input Layer:\n",
    "\n",
    "LeNet-5 takes grayscale images of size 32x32 as input. These images are typically handwritten digits from datasets like MNIST.\n",
    "Convolutional Layers:\n",
    "\n",
    "The architecture consists of two convolutional layers:\n",
    "The first convolutional layer has 6 feature maps with 5x5 convolutional kernels.\n",
    "The second convolutional layer has 16 feature maps with 5x5 convolutional kernels.\n",
    "Each convolutional layer is followed by a subsampling layer (pooling layer) to reduce the spatial dimensions of the feature maps.\n",
    "\n",
    "Subsampling (Pooling) Layers:\n",
    "\n",
    "After each convolutional layer, LeNet-5 uses average pooling layers with 2x2 kernels and a stride of 2. These pooling layers help in reducing the spatial dimensions of the feature maps while preserving the most important information.\n",
    "Fully Connected Layers:\n",
    "\n",
    "Following the convolutional and pooling layers, LeNet-5 has three fully connected layers:\n",
    "The first fully connected layer consists of 120 neurons.\n",
    "The second fully connected layer consists of 84 neurons.\n",
    "The final fully connected layer consists of 10 neurons, corresponding to the 10 output classes (digits 0 through 9 in the case of MNIST).\n",
    "Activation Functions:\n",
    "\n",
    "Throughout the network, LeNet-5 uses the sigmoid activation function, which was common at the time of its development. However, in modern implementations, alternative activation functions such as ReLU (Rectified Linear Unit) are often used for better performance.\n",
    "Output Layer:\n",
    "\n",
    "The output layer uses the softmax activation function to produce probabilities for each class, representing the likelihood of the input image belonging to each digit class.\n",
    "Training:\n",
    "\n",
    "LeNet-5 is trained using the backpropagation algorithm with gradient descent optimization. It uses techniques like weight sharing and parameter tying to reduce the number of trainable parameters and improve generalization.\n",
    "Loss Function:\n",
    "\n",
    "The network typically uses the cross-entropy loss function, which measures the difference between the predicted class probabilities and the true labels.\n",
    "Overall, LeNet-5 demonstrated the effectiveness of CNNs for tasks like handwritten digit recognition and laid the groundwork for more advanced CNN architectures developed later. While it may seem simple compared to modern CNNs, its principles and design choices have had a lasting impact on the field of deep learning.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd76fdc4-280d-4acf-a4a1-a0289ad942b4",
   "metadata": {},
   "source": [
    "Ans 2 )Convolutional Layers:\n",
    "\n",
    "Purpose: These layers apply convolutional filters to the input images to extract important features such as edges, strokes, and textures. Convolution helps in capturing local patterns and spatial hierarchies in the input images.\n",
    "Key Components: LeNet-5 consists of two convolutional layers. The first layer has 6 feature maps with 5x5 convolutional kernels, while the second layer has 16 feature maps with 5x5 convolutional kernels.\n",
    "Subsampling (Pooling) Layers:\n",
    "\n",
    "Purpose: Pooling layers reduce the spatial dimensions of the feature maps obtained from the convolutional layers, making the representations more compact and invariant to small translations and distortions in the input.\n",
    "Key Components: After each convolutional layer, LeNet-5 uses average pooling layers with 2x2 kernels and a stride of 2.\n",
    "Fully Connected Layers:\n",
    "\n",
    "Purpose: These layers combine the features learned from the convolutional and pooling layers to make predictions or classifications. They help in learning high-level representations of the input images and capturing complex patterns.\n",
    "Key Components: LeNet-5 has three fully connected layers. The first fully connected layer consists of 120 neurons, followed by another layer with 84 neurons, and the final output layer with 10 neurons, each representing one of the digits (0 through 9).\n",
    "Activation Functions:\n",
    "\n",
    "Purpose: Activation functions introduce non-linearity into the network, allowing it to learn complex relationships between the input and output. They help in capturing the non-linearities present in real-world data.\n",
    "Key Components: Throughout LeNet-5, sigmoid activation functions were originally used. However, in modern implementations, alternatives like ReLU (Rectified Linear Unit) are often used for better performance.\n",
    "Output Layer:\n",
    "\n",
    "Purpose: The output layer produces the final predictions or classifications based on the features learned by the previous layers. In the case of LeNet-5, the output layer consists of 10 neurons, each representing the probability of the input image belonging to one of the digits (0 through 9).\n",
    "Key Components: The softmax activation function is applied to the output layer to produce a probability distribution over the 10 classes, indicating the likelihood of the input image representing each digit.\n",
    "Training Mechanism:\n",
    "\n",
    "Purpose: LeNet-5 is trained using the backpropagation algorithm with gradient descent optimization. This mechanism enables the network to learn from its mistakes, adjusting its parameters to minimize the difference between predicted and actual labels.\n",
    "Key Components: During training, LeNet-5 learns to update its weights and biases iteratively, based on the gradients of the loss function with respect to these parameters.\n",
    "In summary, the key components of LeNet-5 work together to extract meaningful features from input images, learn hierarchical representations, and make accurate predictions or classifications. The architecture's design choices have had a significant impact on the development of modern CNNs and their applications in various computer vision tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06839d94-3710-4c83-b5ad-6974e40f7169",
   "metadata": {},
   "source": [
    "Ans 3 ) Advantages:\n",
    "\n",
    "Pioneering Architecture: LeNet-5 was a groundbreaking architecture, being one of the first successful CNNs developed for image recognition tasks. Its design laid the foundation for subsequent advancements in deep learning and computer vision.\n",
    "\n",
    "Effective Feature Extraction: LeNet-5's convolutional layers are adept at extracting hierarchical features from input images. By applying convolution and pooling operations, it captures local patterns and spatial hierarchies, making the network robust to variations in input data.\n",
    "\n",
    "Reduced Parameters: LeNet-5 employs weight sharing and parameter tying techniques, reducing the number of trainable parameters. This design choice helps prevent overfitting and improves generalization performance, particularly when training data is limited.\n",
    "\n",
    "Translation Invariance: Through the use of pooling layers, LeNet-5 achieves translation invariance, meaning it can recognize objects regardless of their precise location in the input image. This property enhances robustness to small shifts and distortions in the input data.\n",
    "\n",
    "Efficient Training: LeNet-5 can be trained efficiently using the backpropagation algorithm with gradient descent optimization. Its relatively simple architecture and fewer parameters make it computationally tractable, even with limited computational resources.\n",
    "\n",
    "Limitations:\n",
    "\n",
    "Limited Capacity: LeNet-5 has a shallow architecture compared to modern CNNs. With only two convolutional layers followed by pooling layers, it may struggle to capture complex patterns and variations present in more challenging datasets.\n",
    "\n",
    "Limited Receptive Field: The receptive field (the area in the input image that influences a single neuron in the network) of neurons in LeNet-5 is relatively small. This limitation may restrict the network's ability to capture long-range dependencies and context in large images.\n",
    "\n",
    "Sigmoid Activation: The original LeNet-5 architecture used sigmoid activation functions, which suffer from the vanishing gradient problem. This issue can slow down training and hinder the learning of deep representations, particularly in deeper networks.\n",
    "\n",
    "Dependency on Handcrafted Features: LeNet-5 relies on handcrafted features learned through convolutional and pooling layers. While effective for simple datasets like MNIST, this approach may struggle to adapt to more diverse and complex datasets with higher variability in object appearance.\n",
    "\n",
    "Performance on Modern Datasets: While LeNet-5 achieved impressive results on datasets like MNIST, its performance may be suboptimal when applied to modern, large-scale datasets with more complex and diverse images, such as ImageNet.\n",
    "\n",
    "In summary, LeNet-5's advantages lie in its pioneering architecture, effective feature extraction, and efficient training. However, it also faces limitations in terms of capacity, receptive field, activation functions, dependency on handcrafted features, and performance on modern datasets. Despite its limitations, LeNet-5's contributions to the field of deep learning and image classification are invaluable, and its design principles continue to influence the development of modern CNN architectures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49f17929-67e1-4319-950a-837e5d23ea9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.15.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting flatbuffers>=23.5.26\n",
      "  Downloading flatbuffers-23.5.26-py2.py3-none-any.whl (26 kB)\n",
      "Collecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.4.0)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1\n",
      "  Downloading gast-0.5.4-py3-none-any.whl (19 kB)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.4.0-py3-none-any.whl (7.7 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow) (22.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (4.21.11)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.23.5)\n",
      "Collecting tensorflow-estimator<2.16,>=2.15.0\n",
      "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m43.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting keras<2.16,>=2.15.0\n",
      "  Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.36.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m69.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting libclang>=13.0.0\n",
      "  Downloading libclang-16.0.6-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.9/22.9 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting grpcio<2.0,>=1.24.3\n",
      "  Downloading grpcio-1.60.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m72.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting wrapt<1.15,>=1.11.0\n",
      "  Downloading wrapt-1.14.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (77 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting absl-py>=1.0.0\n",
      "  Downloading absl_py-2.1.0-py3-none-any.whl (133 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.7/133.7 kB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard<2.16,>=2.15\n",
      "  Downloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting ml-dtypes~=0.2.0\n",
      "  Downloading ml_dtypes-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m61.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow) (65.5.1)\n",
      "Collecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m11.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow) (0.38.4)\n",
      "Collecting markdown>=2.6.8\n",
      "  Downloading Markdown-3.5.2-py3-none-any.whl (103 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m103.9/103.9 kB\u001b[0m \u001b[31m17.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting werkzeug>=1.0.1\n",
      "  Downloading werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-auth-oauthlib<2,>=0.5\n",
      "  Downloading google_auth_oauthlib-1.2.0-py2.py3-none-any.whl (24 kB)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m77.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.28.1)\n",
      "Collecting google-auth<3,>=1.6.3\n",
      "  Downloading google_auth-2.28.0-py2.py3-none-any.whl (186 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m186.9/186.9 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting cachetools<6.0,>=2.0.0\n",
      "  Downloading cachetools-5.3.2-py3-none-any.whl (9.3 kB)\n",
      "Collecting rsa<5,>=3.1.4\n",
      "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
      "Collecting pyasn1-modules>=0.2.1\n",
      "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting requests-oauthlib>=0.7.0\n",
      "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (1.26.13)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.1.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2022.12.7)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.1)\n",
      "Collecting pyasn1<0.6.0,>=0.4.6\n",
      "  Downloading pyasn1-0.5.1-py2.py3-none-any.whl (84 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.9/84.9 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
      "Installing collected packages: libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, pyasn1, opt-einsum, ml-dtypes, markdown, keras, grpcio, google-pasta, gast, cachetools, astunparse, absl-py, rsa, requests-oauthlib, pyasn1-modules, google-auth, google-auth-oauthlib, tensorboard, tensorflow\n",
      "Successfully installed absl-py-2.1.0 astunparse-1.6.3 cachetools-5.3.2 flatbuffers-23.5.26 gast-0.5.4 google-auth-2.28.0 google-auth-oauthlib-1.2.0 google-pasta-0.2.0 grpcio-1.60.1 keras-2.15.0 libclang-16.0.6 markdown-3.5.2 ml-dtypes-0.2.0 opt-einsum-3.3.0 pyasn1-0.5.1 pyasn1-modules-0.3.0 requests-oauthlib-1.3.1 rsa-4.9 tensorboard-2.15.2 tensorboard-data-server-0.7.2 tensorflow-2.15.0.post1 tensorflow-estimator-2.15.0 tensorflow-io-gcs-filesystem-0.36.0 termcolor-2.4.0 werkzeug-3.0.1 wrapt-1.14.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09e467c2-3835-4968-9871-b6740e28c686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "24796286-7a7f-41e3-88d7-9ef5bcda9070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_2 (Conv2D)           (None, 24, 24, 6)         156       \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPoolin  (None, 12, 12, 6)         0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 8, 8, 16)          2416      \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPoolin  (None, 4, 4, 16)          0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 256)               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 120)               30840     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 84)                10164     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 10)                850       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 44426 (173.54 KB)\n",
      "Trainable params: 44426 (173.54 KB)\n",
      "Non-trainable params: 0 (0.00 Byte)\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, datasets\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load and preprocess the MNIST dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0  # Normalize pixel values to [0, 1]\n",
    "\n",
    "# Add a channel dimension to the images (required by LeNet-5)\n",
    "train_images = train_images[..., tf.newaxis]\n",
    "test_images = test_images[..., tf.newaxis]\n",
    "\n",
    "def LeNet5():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(6, kernel_size=(5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(layers.Conv2D(16, kernel_size=(5, 5), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(120, activation='relu'))\n",
    "    model.add(layers.Dense(84, activation='relu'))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    return model\n",
    "\n",
    "# Create an instance of LeNet-5 model\n",
    "model = LeNet5()\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Print model summary\n",
    "model.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42474a54-7b8f-4e63-9c5e-7a381d7ce444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.1929 - accuracy: 0.9405 - val_loss: 0.0568 - val_accuracy: 0.9815\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0622 - accuracy: 0.9814 - val_loss: 0.0588 - val_accuracy: 0.9824\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0468 - accuracy: 0.9854 - val_loss: 0.0394 - val_accuracy: 0.9879\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0362 - accuracy: 0.9887 - val_loss: 0.0376 - val_accuracy: 0.9882\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0294 - accuracy: 0.9907 - val_loss: 0.0500 - val_accuracy: 0.9843\n",
      "Epoch 6/10\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0257 - accuracy: 0.9918 - val_loss: 0.0484 - val_accuracy: 0.9863\n",
      "Epoch 7/10\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0206 - accuracy: 0.9938 - val_loss: 0.0318 - val_accuracy: 0.9911\n",
      "Epoch 8/10\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0182 - accuracy: 0.9944 - val_loss: 0.0305 - val_accuracy: 0.9906\n",
      "Epoch 9/10\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0159 - accuracy: 0.9947 - val_loss: 0.0453 - val_accuracy: 0.9878\n",
      "Epoch 10/10\n",
      "1875/1875 [==============================] - 12s 7ms/step - loss: 0.0159 - accuracy: 0.9948 - val_loss: 0.0363 - val_accuracy: 0.9899\n"
     ]
    }
   ],
   "source": [
    "# Train the model\n",
    "history = model.fit(train_images, train_labels, epochs=10, validation_data=(test_images, test_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f49b308c-1d9f-4b65-bdc8-39d9b6291555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.0363 - accuracy: 0.9899\n",
      "Test Accuracy: 0.9898999929428101\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAGwCAYAAABB4NqyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAABjcUlEQVR4nO3deXxMV/8H8M9kMkkmq0jIIrsllqglCIJSLWKp6EYflEfpo0WpbvKgiyotDbqQ1hK0tKJVrV/rKWnRIkilDSIau5BFJMi+TGbu74+bmRhZZJnkZjKf9+s1L5k7986cm2jzcc73nCMTBEEAERERkQkxk7oBRERERI2NAYiIiIhMDgMQERERmRwGICIiIjI5DEBERERkchiAiIiIyOQwABEREZHJMZe6AU2RRqNBamoq7OzsIJPJpG4OERER1YAgCMjNzYW7uzvMzKrv42EAqkRqaio8PT2lbgYRERHVwfXr1+Hh4VHtOQxAlbCzswMgfgPt7e0lbg0RERHVRE5ODjw9PXW/x6vDAFQJ7bCXvb09AxAREZGRqUn5CougiYiIyOQwABEREZHJYQAiIiIik8MARERERCaHAYiIiIhMDgMQERERmRwGICIiIjI5DEBERERkchiAiIiIyOQwABEREZHJYQAiIiIik8MARERERCaHm6ESERGZMEEQIAiAoP0aKHsuHgcATRXn4J7zKrseuuPic41Q/nmW5mZobW8lzU2DAYiIiMigStUaFJVqUFiiRpFKjUKVGoUlZX+q1Ci652v9czTi6/eff8/zIpUaas09IaMscKCKAKJ5QEiRUk+vFvj+pWDJPp8BiIiITIIgCCguCyaVB5D7A0cVgaSa64tUGpSoNVLfapMhkwEyADKZDGYyQAbxgAyAhbm0VTgMQEREZDQEQUBBiRp3C1W4W1CC7AJV2dcqZBeqcLew7FiB+LX2eHahCoUqdaP3eigVcigt5FAq5LBSmN3ztfy+18q/VirksLrna6WFme58K4UccjNZWagAAJleyNAel2mPy6o4Ll6q9/z+8yArDzBmMpne9ajk/fSu157UhDEAERFRo9NoBOQWlepCyt2ykJJdUP5cDC8Vn6vU9U8xFnKzioGkygByT2Apu+ZBAUZpIYeluZlRBAFTxQBERER1plJrxJ4XXU9LWWDRhpqCEl14ufd5dqGqXr0xCrkMLawt0EKpQAtrBRyUFnAo+1p3TO91BawtzMXwYm4GczknQZs6BiAiIqqgSKVG/PW7OHMjG3e0oeWeYSVt4MkrLq3X51hbyNFCqR9WWlgrYK9UoIXSQhdoHKzveW6tgFIhZ+8K1QsDEBERobhUjfjkuzh2OQvHL2fhr+S7KCmteTGvvZW52CNT1tvS4r7eF92xewKNg1IBS3N5A94VUdUYgIiITFBxqRqnrmfj+OUsHLuUhb+S76D4vsDTys4SvX0c4WJvpet9cdD1xpSHHHulAnIz9saQcWEAIiIyASWlGpy6cRfHL2Xh+JUsxF27gyKVfuBxtrVEX7+W6NfWCX39nODnbMNhJmq2GICIiJqhklINzqTcxbFLWTh++TZOXrtdSeCxQJCfGHb6+TmhbSsGHjIdDEBERM2ASq3B6RvikNbxy1k4efUOClVqvXOcbCzQ188Jff1aoq+fE9q1tmXgIZPFAEREZIRUag3OpJTX8MRdu4OCEv3A09LGQhd2+vo5oT0DD5EOAxARkREo1QWe2zh2OQsnr96uEHgcrRUI8nXS1fC0b20LMxYnE1WKAYiIqAkqVWuQkJqjG9L688pt5N8XeFpYKxDkK/bw9GvrhA6t7Rh4iGqIAYiIqAkoVWtw9t7Ac/VOhUUGHZT6gcffhYGHqK4YgIiIJKDWCEhMzcGxy5k4fvk2/rxyG7n3BR57K3PdLK2+fi3RydWegYfIQBiAiIgagVoj4Fxajq5oObaSwGNnZa7r4enr54RObvZcYJCogTAAERE1gHsDz/HLWThx5TZyi+4LPJbm6ONbvvAgAw9R42EAIiKqh5wiFa5lFuBqVj6SbxfgamY+rmUV4J/0HOTcF3hsywJPX7+W6OfnjM7uDDxEUmEAIiKqhiAIuFOgwtWsfFzLEsPNtayCsucFuJ1fUuW1tpbm6O3jqBvS6uJuD3O5WSO2noiqwgBERCZPEATcyi3GVV2w0Q869w9d3c/Z1gLeTjbwdrKGT9mffs626ORmx8BD1EQxABGRSdBoBKTlFOFaZj6uZhXgWla+rhfnWlZBhW0j7udqb1UecJzLg463kw1sLfm/UiJjw/9qiajZKFVrkHK3sDzgZIp/XrtdgOTbBSgp1VR5rZkMcG+h1AUb3Z/ONvB0tIbSQt6Id9JE5KYDF/YDcgvAykH/YWkPWNoB3FqDjBQDEBEZleJSNa7fLizrwSnQ/ZmclY8bdwpRqhGqvNbcTAbPltb6AafsTw9Ha1iYc7gKAFBaApz4HPj9Q6Akr+rzZGZiELo/HN0flCp9zV58zcwEgyU1CQxARNTkFJSUls2oKtALOteyCpCaXQih6owDS3MzeDtZw6ulDXycrOHtLP7p42QDNwcr1uQ8yKUDwP/eBDLPi89dugI2zkBxDlCULT4K7wIaFSBogKK74qOu7g1IlYalSo5Z2gNWLcTX5Ir63zOZJAYgIpKUdkXkE1fE9XJO38hGRm5xtdfYWMh1RcfeTmVBx8kGPs7WcLGz4mrJdXE3Gdi3EDi3R3xu0wp49F2g27OA2X2hURCA0iKg6J5QVJRdFoay9cOS7nHfsdJC8b2Kc8RH9vW6tVthU3VQujdUWbcEvAcANk51/hZR88IARESNqlStQWJaDk5cvo3jl7MQe7XiAoGAuA2Er7MNvO4NOGV/OttaQMbaE8NQFQExnwKHw8VQIpMDfV4ABi8AlC0qv0YmAxRK8WHnUrfPLS25JyjdrT4sVRaqtENzqnzxkZv64M80Mwf8hgABTwIdR4mhiUyW5AFo3bp1WLlyJdLS0tClSxesWbMGAwcOrPL8tWvX4rPPPsPVq1fh5eWFhQsX4rnnntO9rlKpsHz5cmzduhUpKSnw9/fHhx9+iBEjRjTG7RDRfbSbfIo9PJXveaVdETnIryUCvVuibSsbtLC2kKjFJkIQgPO/AL8sAO5cFY95DwBGrgRcOjf855tbAObO4vBaXahLK+9pqrT3KRu4cw3IOAtcjBYfckugwzAg4Cmgw3AxzJFJkTQARUVFYd68eVi3bh2Cg4PxxRdfICQkBImJifDy8qpwfkREBMLCwrBhwwb07t0bsbGxmDFjBhwdHTFmzBgAwKJFi7Bt2zZs2LABHTt2xL59+zBu3DjExMSgR48ejX2LRCanVK1BQmoOTlSzq7l2z6sgX3GBQK6I3MiyLonB58J+8bmdOzB8KdDlCeOZ1SU3F4e1rFvW/JrMC0DCLuDMd0DWBeDc/4kPC1uxRyjgKaDtENYVmQiZIFRXTtiwgoKC0LNnT0REROiOderUCaGhoVi+fHmF8/v374/g4GCsXLlSd2zevHk4efIkjhw5AgBwd3fHwoULMWvWLN05oaGhsLW1xbZt2yptR3FxMYqLy2sOcnJy4OnpiezsbNjbs4uUqDrawKPd8+pkJYHH3socfXzFHc2555WESvLFoa6YTwF1CWCmAPrPBga+BljaSt26xiMIQPoZMQwlfA9kJ5e/pnQEOo8Vh8m8gzlLraGoVWIxvW0rg75tTk4OHBwcavT7W7IeoJKSEsTFxWHBggV6x4cNG4aYmJhKrykuLoaVlZXeMaVSidjYWKhUKigUiirP0QakyixfvhzvvvtuHe+EyLSo1BokpGTjeFkNz8mrt5Ffor+IIANPEyMIwNndwP5FQE6KeKzdo8CIDwHndtK2TQoyGeD2kPh49B3geqwYhs7uBvIzgLgt4sPWFegyDuj6FNAm0Hh6x5oijQa4eQa4/Dtw5Q/gWgzQ/lHgmS8la5JkASgzMxNqtRouLvoFdC4uLkhPT6/0muHDh2Pjxo0IDQ1Fz549ERcXh8jISKhUKmRmZsLNzQ3Dhw/HqlWrMGjQILRt2xa//fYbfvzxR6jVVa/yGhYWhvnz5+uea3uAiEgMPGdSsst6eG7j5NXbKLgv8DgoFWWbfIqhp6MrA0+TkXEO2Ps6cPWw+LyFNzDiA8A/hL/QAfF74BUkPoYvA64dEYfIzu0B8tKBExHio4W32CvU9SmgdWd+7x5EEMQhxyu/i4+rR4DCO/rnZJwTz5Poeyl5EfT9MzkEQahydsfixYuRnp6Ovn37QhAEuLi4YOrUqVixYgXkcrGb8uOPP8aMGTPQsWNHyGQytG3bFv/+97+xefPmKttgaWkJS0tLw90UkRFTqTU4fSNbN6QVd+1OhcDTwlqBPj4tdZt8dnS149TzpqYoGzj0obigoaAGzK2AAfOB4JdZ8FsVuTngN1h8jFoFXPpN7Bn6Zy9w9xpwZJX4aNVRrBcKeAJwait1q5uOu9fLAs8f4iM3Tf91CzvAJxjwHQT4Pix5kJQsADk7O0Mul1fo7cnIyKjQK6SlVCoRGRmJL774Ajdv3oSbmxvWr18POzs7ODuLMwlatWqFH374AUVFRcjKyoK7uzsWLFgAX1/fBr8nImNUUqrBmZS79wxp3amwL5aj9b09PE7wd2HgabI0GuD0DiD6bXE4BwA6jhZ7Nxy9pW2bMTG3EHvJ/EPE2qnzv4j1Qhf2A7f+AQ4uFR/uPcSeoS5PAA5tpG5148q7BVwtCzuXfwfuXNF/XW4p9qz5Piw+3HuIIbOJkKwlFhYWCAwMRHR0NMaNG6c7Hh0djbFjx1Z7rUKhgIeHBwBgx44dGD16NMzuW6jLysoKbdq0gUqlwq5du/DMM88Y/iaIjFBJqQanb9zVDWnFXas88ARpa3jaOqFDawYeo5AaLw533YgVnzu1B0I+BNoNlbRZRs/CRgw5AU+Khbv//AwkfCf+0k/9W3zsXwx49xd7hTqH1n16f1NWlC3W7mjreDLO6r8ukwNtepYFnkGAZxCgsKr8vZoASWeBRUVFYfLkyfj888/Rr18/rF+/Hhs2bMDZs2fh7e2NsLAwpKSk4MsvxSKp8+fPIzY2FkFBQbhz5w5WrVqF6OhoxMXFwcfHBwBw4sQJpKSkoHv37khJScE777yDK1eu4K+//kKLFi1q1K7aVJETNXXFpWpxSOtSFo5fEYe0ilT6m4K2tLFA0D09PO1b2zLwGJOC28CB94CTmwEI4urIg98Egl4UezKoYeTdAhJ/EIfJko+VH5fJxWG0rk+VLbjoIFUL60dVCCQfLx/SSv1L3P7kXi5dxbDj9zDg1U/yxSWNYhYYAIwfPx5ZWVlYsmQJ0tLSEBAQgL1798LbW+ymTUtLQ3Jy+fREtVqN8PBwJCUlQaFQYMiQIYiJidGFHwAoKirCokWLcPnyZdja2mLkyJH46quvahx+iIxdcakap66LNTwnqgk82hlaff2c0K4VA49R0qjF2UoH3isvMO36NPDYEsDeXdKmmQTbVkCfGeIj+4Y4RJawC0iLF+uHLv0mDgO1f0wMQ+2HAxbWUre6amoVkPJXWeD5Hbh+Qlwu4V4t24phx3cQ4DPQqHu6JO0BaqrYA0TG5mxqNn47l6ErWi4u1Q88TjYWuhlaff2c0K61LbeSMHbXY4GfXwXST4vPXQKAkBVikSlJK/MicPZ7cTZZZlL5cQtbwH+kOJTW9hHpe+c0GuBmQnnh8rWY8i1GtOzcywOP7yDAwUOattZQbX5/MwBVggGIjEFBSSl+OpWG7Seu4dSNbL3XnG0tEFTWu9PXtyUDT3OSexP49R3g1Nfic0sH4JFFQK9pTarAlCBO8b55VqwXStglbjirpXQEOj0uhiGfAY2z4KIgAFkXxcBz+XdxaYT7p6YrWwK+A8sLl53aGtWUfwagemIAoqbs/M1cfH0iGbv+uqHbRFQhl2FoRxcEt3dGP7+WaNuKgafZUauA2PXAoQ/E/a4AoMdkYOjbBl9NlxqAIAA3Toph6OxuIO9m+Wu2LuKCiwFPAR69DBs4sm+Uz9K68kfFTWMtbMUVr7V1PK27APdNKjImDED1xABEktOoxQLE0iJAVYDiwnzE/HMDB85cw5X0TFihBEoUo42tDMHe1ujpbgWblu7i7JMmPOuC6ujy78D/3hCnXwOAe09g5EeAR6C07aK60ajFhQETdgGJPwJFd8tfa+FVNuPsKcClS+3DUH5medHyld+B25f1X5dbAp59yoa1tFPTm8/eZwxA9cQARJW6L5RAVfZnpc8Lyx+lhVU8r+R87Wv3Fx7WlK2ruLdT4L9Na2+n5ir7hrh9xdnd4nNrJ3Hrhu6TjPpf6XSP0hLg0oGyBRd/BlT55a85+4vF0wFPVr3gYlGOWLujreO5maD/um5q+qB7pqY334UwGYDqiQHIRKhLgZObxG7phgwl9VQkKFAIS6hkFrCwsoGNrR0Ultbi/8S0D3Mr4OpRIOeGeJGyJdD3JXF2irKFJO2meigtFjcsPRwu/n2UmQG9pwND/ivWjlDzVFIAXNgnFk9fiAbU5Zt0w627GIQ6jdZfcTnlL3Gl73u5BJSvtuzdz3in4dcBA1A9MQCZgFvngd3/Ede1qAtzK/GhsBaHnBTWZc/vDSXKKp7fe3759TcLgZ8S72J3wm3cyAOKYIESmQIPd3DBxCBvDPZvBXN5Nf/qLy0RVwA+srq829vSXgxBfV8y6umqJuX8fuCXN8t/hl79gJErAdeu0raLGldRdtmCi7uASwcrhpx7tfQrX3zQd5BJ/7fOAFRPDEDNmEYjbmz42xKxl8fKAeg7C7Bxqhhiqgow5lYGG35QawQcSsrA9hPJOJiUAe1/jc62lpjQ2xPje3vCs2Ut1w1Rl4qLs/3xEXDrnHhMYQ0ETgX6z+H6ME3V7cvAL/8Fzv9PfG7rCgx7T1zXhwXtpi0/s2zBxe+Ba0cBOzf9wNOCm3drMQDVEwNQM3X7CvDjLPF/IADQ7lHg8U8lCQQ3c4oQ9ed17IhNRmp2ke54cDsnTAzyxmOdXaCorrenJjQaIGkvcPgjcal+AJBbAN0nAgPmAY4+9Xt/MoySArHX7ujH4pCHmbnYY/fwG4ClndSto6ZGVQSYWzIUV4EBqJ4YgJoZQQDiNgP7FokFhha2wPD3gZ5TGvV/IhqNgKOXMrH9eDKiz92EWiP+p+dorcBTgR54to8X/Fo1QOGyIIgr0v4RDiTHiMdkcuChZ8TdwVt1MPxn0oMJAnBuD7BvIZB9XTzmNxgIWcmfCVEdMQDVEwNQM5KdAuyZLc6yAADvAUDo2kbt/cjKK8Z3cTfwdWwyrmUV6I739nHExCBvjAhwhZWiERZBA8RC6cMflX8/IAM6jwUGvgq4PdQ4bSDgVpI4rf3yIfG5g6e4W3unMfyXPVE9MADVEwNQMyAIwKkdwP/eBIqzxbqdR98B+vynUaYPC4KA2Cu3sf1EMn5JSEeJWtyaws7SHE/0bIN/BXnD31XC4Y2UOLFHKOnn8mPthwODXhPXCKGGUZQD/LECOB4BaErFNVkGzAOC5zXtPaKIjAQDUD0xABm5vAzg/+aV/3Jv0wsY9zng3L7BPzq7QIXv/76B7SeScTGjfE+dbh4O+FeQF8Z0c4e1RRParuDmWeDwKnHfIu0uz76DgEGvixsdsjfCMAQBOL0TiF5cvgKw/0ix16elr7RtI2pGGIDqiQHIiJ39AfjpFaDwNmCmAIaEAf3nNugeSYIgIP76XXx9Ihn/dzpVt/O6UiFHaA93/KuPN7p6NPF1OLIuAUdWib1mGnF7DXj0EXuE2g9jEKqPtNPicFfyMfF5Sz9gxIdAh2HStouoGWIAqicGICNUcBvY+7q4zw4AuHQVe31cAxrsI/OKS/FjfAq2H09GYlqO7nhHVztMDPLC2B5tYG9lZEvM300Gjn4C/PVl+SJsrl2Bga+JGzdy9eGaK7gNHFwmLrYpaMSlCAa9BvSbLc7iISKDYwCqJwYgI3N+H7DnZSAvXZzdNHA+MOgNwNyiQT7ubGo2vj6RjB/+TkF+ibg4mYW5GUY/5IaJQV7o6eVo/BuR5t4Ejn0G/LmpfGl+5w5isXTAU9x1vCpF2UDycXGX7fivgYIs8XiXccCwpYCDh7TtI2rmGIDqiQHISBTlAPv+C/z9lfjcuQMQ+nmDbBBZWKLGT6dTsf1EMuKv39Ud93O2wb+CvPBUoAdaWDdM4JJUwW3gxOfioyhbPNbCWyzc7T6RPRkFt8WhratHgWtHgPQz5bVUANCqEzByhVhXRUQNjgGonhiAjMDl38VFDbOvA5AB/WYBjywy+CZ/FzNysf1EMnbF3UBOkVgbo5DLMLyLKyYGeaOvX0vj7+2piaIc4M+NwLG1QEGmeMzODej/MhA4BbCwkbZ9jSU/S1xI89pRMfTcTABw3/9CW7YFfILFlXo7j21WO20TNXUMQPXEANSElRQAv74DxH4hPm/hDYRGiL9wDKS4VI1fEtLx9YlknLhyW3fcw1GJfwV54elAT7SyM9Gej5ICsT7o6MdAbqp4zNpJDKC9pze/TRfzbok9O1fLQk9GYsVznDsA3sGAzwDxT3u3xm8nEQFgAKo3BqAmKvkE8MOLwO1L4vNe04DH3gMsDbN68rWsfHwdm4xvT97A7Xxx53czGTC0kwsmBnlhUPtWMDMzgd6emigtBk59I27hcOeqeMzSAQh6AQh6UdxbzRjlpgNXj5T38GQmVTynVScxcHuXPexcGr+dRFQpBqB6YgBqYkqLxdk0MZ+I9RV27sDYT8W9vOpJpdbgt3MZ2H7iGg5fyNQdd7W3woQ+4makbg6GHVZrVtSl4m7Vh8PLw4LCBuj1b3HjVTtXadv3INkpZWGnLPRkXax4jktAWQ9PWeAx4Z22iZo6BqB6YgBqQlLjgd0zy3c17/YsMOIDQNmiXm9bXKrGzpM3EHHwom4zUpkMGNS+FSYGeeGRjq1hXt/NSE2JRgP88xPwx0og/bR4TG4J9JwMBM8FWnhJ2z6tu8nlBctXjwJ3rtx3gkyc9q8dzvLuD1i3lKSpRFR7DED1xADUBKhVYq/CHyvFhflsWgGj1wCdRtfrbYtUakT9eR0Rhy4hPUcMPk42Fnimtyee7e0FLyduR1AvggBc/FX8uV0/IR4zMwceGi9uvOrcrnHbcudq+XDWtSNiALqXzAxw61Zew+PVF1A6Nl4bicigGIDqiQFIYhnnxF6ftHjxeafHgdGr6zX0UKRS4+sTyfj890vIyBUX+HO1t8KLg9tifG/PxtuM1FQIgjisdPij8g0/IRPXwxn4asMsUCkIwO3L+jU8OTf0z5HJAfceZcNZAwCvoOZXuE1kwhiA6okBSCIatbj43oGlgLoEsGoBjAoHAp6s81YMhSVqbD9xDZ//fhmZeWLwcXewwotD2uGZXh6wNGfwaXA3TgJ/fASc/1/5Mf+R4urS9VmzSRCAzAv6s7Ry0/TPMTMH2gSW1/B4BgGWEm5CS0QNigGonhiAJJB1SZzhpR02aT8cGPNxnacU5xeXYtvxa9hw+DIy88QZXW1aKDFrSDs8GdiGwUcK6WfEYc2zP0C3do7fEHF7CO/gB4dcQQBu/aPfw5OfoX+O3ELc/FZbsOzZx3TWKCIiBqD6YgBqRBqNuFdS9FuAqgCwsANGLAd6TKpTr09ecSm+PHYVGw9f0U1l92ypxOwh7TCuhwcszFnYLLnMC+L0+VM7AEHcSgSefcUg1O7R8p+7RiOuu3PvLC3t1hJacksx5Gh7eDx6G3wxTCIyHgxA9cQA1EjuXhdXc77yu/jcZyAQuq5OM4Zyi1TYGnMVG49cwd0CFQDA28kas4e0Q2iPNlBwRlfTc+eauKDi39vKN1516ybWfKX+LQaewjv615grxcCjnaXVJhBQWDV+24moSWIAqicGoAYmCED8duCXMKA4R/yl9tgScSXhWu42nl2owpajV7HpyGXdVhV+zjaY/Ug7PN7NnVPZjUFOmlj7dTJS7AW8l8JGLFTWztJy79lgm9wSkfFjAKonBqAGlJsO/N9c4Pwv4nOPPsC4zwGntrV6m+wCFTYdvYLNR68gtyz4tG1lg5eHtsfoh9wh54rNxic/S9ziJCOxrHB5AODenXtpEVGN1eb3t3kjtYlIXDH451fFYQ25BTBkobhasFnNC5Lv5Jdg05Er2BJzFXnFYvDp4GKLOY+0x8iubgw+xszGCRjyX6lbQUQmggGIGl5+FrD3VeDsbvG560PAuC8Al841fovb+SXYcPgyvoy5ivwSsXC2o6sdXh7aHiO6uHKPLiIiqhUGIGpY/+wVh7zyM8RF6Aa9Ls72qeGwRmZeMTb8cRlfHb+GgrLg09nNHi8PbY9hnV0YfIiIqE4YgKhhFGWLRc7x28XnrTqKtT7uPWp0eUZuEdb/fhnbTlxDkUoDAAhoY4+5Qzvg0U6tIavjwohEREQAAxA1hEsHgB9nAzkpAGRinc+QhTWarnwzpwif/34JX59IRnGpGHy6eThg7qPtMcSfwYeIiAyDAYgMpzhPXNDw5CbxuaOv2Ovj1feBl6ZlF+LzQ5fwzZ/XUVIWfHp4tcDcoe3xcIdWDD5ERGRQDEBkGNdixK0s7lwVn/eeATz27gO3IUi5W4iIQxex888bKFGLwaeXtyPmPtoeA9o5M/gQEVGDYACi+lEVAQfeA46tBSAA9h7A2M+AtkOqvez67QJE/H4J3568DpVaXIqqj29LzBvaHv3aOjH4EBFRg2IAorpLiQN2vwhkJonPu08CRiwDrByqvCQ5qwDrDl3Ed3E3UKoRg08/Pye8XBZ8iIiIGgMDED2YRgMUZALZN4CcVLG4OeMc8NeX4maWti7AmE8A/xFVvsXVzHysPXgR3/+dAnVZ8BnQzhkvD22PPr4tG+tOiIiIADAAUWXhJicFyE4pe35D3KtJo6r8+i5PAKPCAevKQ8zlW3n47OBF/Bifqgs+gzq0wtyh7RDozeBDRETSYABqzh4YblKA3DRAXVKDN5MBdq6AvXvZwwPwG1xlr8/FjFx8duAi9pxKRVnuwRD/VpgztD16ejka7BaJiIjqggHIWFUIN9remtSygFPLcGPrAji0KQ839u5lz8sedq41Wr35/M1cfHrgIn46nQrtNruPdmqNOY+0RzfPFvW6ZSIiIkNhAGqKtOGmwlCUIcKNNtS4Aw5lQcfOrd47bp9Ly8FnBy5ib0KaLvgM6+yCl4e2R0CbqouiiYiIpMAA1NgaItzc31tj4HBTnbOp2fjktwvYd/am7lhIgCtmP9IOXdwZfIiIqGliAGpMV/4Atj1Z+3Bzb6DRhhyHNoCtK2Bu0eDNrsy5tByE7z+PX8+JwUcmA0Z2dcOcR9qho6u9JG0iIiKqKQagxmTtVBZ+ZIBt64q9NU0k3DzI3YISTFh/HNmFKshkwJiH3DH7kXbo4GInddOIiIhqhAGoMTm1B+aeFoelmmi4qYm/k+8iu1AFNwcrfPV8ENq1tpW6SURERLXCANSYzC0AR2+pW1FvCSnZAMStKxh+iIjIGJlJ3QAyPmfKAlBXzu4iIiIjxQBEtabtAeL0diIiMlYMQFQrWXnFSM0uAgB0dudsLyIiMk6SB6B169bB19cXVlZWCAwMxOHDh6s9f+3atejUqROUSiX8/f3x5ZdfVjhnzZo18Pf3h1KphKenJ1555RUUFRU11C2YlITUHACAr7MN7K0abn0hIiKihiRpEXRUVBTmzZuHdevWITg4GF988QVCQkKQmJgILy+vCudHREQgLCwMGzZsQO/evREbG4sZM2bA0dERY8aMAQBs374dCxYsQGRkJPr374/z589j6tSpAIDVq1c35u01Sxz+IiKi5kDSALRq1So8//zzmD59OgCx52bfvn2IiIjA8uXLK5z/1Vdf4T//+Q/Gjx8PAPDz88Px48fx4Ycf6gLQsWPHEBwcjH/9618AAB8fHzz77LOIjY2tsh3FxcUoLi7WPc/JyTHYPTY3ugDE4S8iIjJikg2BlZSUIC4uDsOGDdM7PmzYMMTExFR6TXFxMaysrPSOKZVKxMbGQqVSAQAGDBiAuLg4XeC5fPky9u7di1GjRlXZluXLl8PBwUH38PT0rM+tNWucAUZERM2BZAEoMzMTarUaLi4uesddXFyQnp5e6TXDhw/Hxo0bERcXB0EQcPLkSURGRkKlUiEzMxMAMGHCBLz33nsYMGAAFAoF2rZtiyFDhmDBggVVtiUsLAzZ2dm6x/Xr1w13o83InfwS3LhTCADowgBERERGTPKFEGUymd5zQRAqHNNavHgx0tPT0bdvXwiCABcXF0ydOhUrVqyAXC4HABw6dAjvv/8+1q1bh6CgIFy8eBFz586Fm5sbFi9eXOn7WlpawtLS0rA31gydLSuA9mppDQclC6CJiMh4SdYD5OzsDLlcXqG3JyMjo0KvkJZSqURkZCQKCgpw9epVJCcnw8fHB3Z2dnB2dgYghqTJkydj+vTp6Nq1K8aNG4dly5Zh+fLl0Gg0DX5fzRmHv4iIqLmQLABZWFggMDAQ0dHResejo6PRv3//aq9VKBTw8PCAXC7Hjh07MHr0aJiZibdSUFCg+1pLLpdDEAQIgmDYmzAxCamcAUZERM2DpENg8+fPx+TJk9GrVy/069cP69evR3JyMmbOnAlArM1JSUnRrfVz/vx5xMbGIigoCHfu3MGqVauQkJCArVu36t5zzJgxWLVqFXr06KEbAlu8eDEef/xx3TAZ1U35FHjOACMiIuMmaQAaP348srKysGTJEqSlpSEgIAB79+6Ft7e4YWhaWhqSk5N156vVaoSHhyMpKQkKhQJDhgxBTEwMfHx8dOcsWrQIMpkMixYtQkpKClq1aoUxY8bg/fffb+zba1ayC1W4llUAAAhwZw8QEREZN5nAcaEKcnJy4ODggOzsbNjbs7cDAGIuZeJfG07Aw1GJI28+InVziIiIKqjN72/Jt8Ig41C+ACJ7f4iIyPgxAFGNnEkRp8B39WAAIiIi48cARDVylnuAERFRM8IARA+UW6TC5cx8ANwDjIiImgcGIHog7QrQ7g5WcLLlitlERGT8GIDogRI4/EVERM0MAxA9EAMQERE1NwxA9EDcA4yIiJobBiCqVn5xaXkBNAMQERE1EwxAVK3EtBwIAuBib4lWdiyAJiKi5oEBiKp15gaHv4iIqPlhAKJqJaSyAJqIiJofBiCqFvcAIyKi5ogBiKpUUFKKixl5ALgHGBERNS8MQFSlc2m50AhAKztLuNhbSd0cIiIig2EAoiqVD39x/y8iImpeGICoSlwAkYiImisGIKoSt8AgIqLmigGIKlWkUuNCWQE0AxARETU3DEBUqXNpOVBrBDjZWMDNgQXQRETUvDAAUaUSUnMAiL0/MplM4tYQEREZFgMQVSrhhrb+hzPAiIio+WEAokpxBhgRETVnDEBUQXGpGudv5gJgATQRETVPDEBUQVJ6Lko1AlpYK9CmhVLq5hARERkcAxBVcO/wFwugiYioOWIAogoSUspngBERETVHDEBUQfkeYAxARETUPDEAkZ6SUg2S0sUCaM4AIyKi5ooBiPScv5mLErUG9lbm8GzJAmgiImqeGIBIz70boLIAmoiImisGINLDBRCJiMgUMACRnnv3ACMiImquGIBIR6XW4FwaAxARETV/DECkc+FmHkpKNbCzNId3S2upm0NERNRgGIBIJyFVrP/p0sYeZmYsgCYiouaLAYh0uAAiERGZCgYg0tHNAPNgACIiouaNAYgAAKUsgCYiIhPCAEQAgEu38lGk0sDGQg5fJxupm0NERNSgGIAIQPnwVxd3BxZAExFRs1frAOTj44MlS5YgOTm5IdpDErl3CwwiIqLmrtYB6NVXX8WPP/4IPz8/PPbYY9ixYweKi4sbom3UiMoDkL3ELSEiImp4tQ5Ac+bMQVxcHOLi4tC5c2e8/PLLcHNzw+zZs/HXX381RBupgak1As6WbYHBPcCIiMgU1LkGqFu3bvj444+RkpKCt99+Gxs3bkTv3r3RrVs3REZGQhAEQ7aTGtCVzDwUqtRQKuTwa2UrdXOIiIganHldL1SpVNi9ezc2b96M6Oho9O3bF88//zxSU1OxcOFC/Prrr/j6668N2VZqINoC6M7u9pCzAJqIiExArQPQX3/9hc2bN+Obb76BXC7H5MmTsXr1anTs2FF3zrBhwzBo0CCDNpQazpkbHP4iIiLTUusA1Lt3bzz22GOIiIhAaGgoFApFhXM6d+6MCRMmGKSB1PC0e4BxBhgREZmKWgegy5cvw9vbu9pzbGxssHnz5jo3ihqPRiMgMVW7AjRngBERkWmodRF0RkYGTpw4UeH4iRMncPLkSYM0ihrPlax85BWXwkphhnYsgCYiIhNR6wA0a9YsXL9+vcLxlJQUzJo1yyCNosajXf+nk5s9zOVcGJyIiExDrX/jJSYmomfPnhWO9+jRA4mJibVuwLp16+Dr6wsrKysEBgbi8OHD1Z6/du1adOrUCUqlEv7+/vjyyy/1Xh88eDBkMlmFx6hRo2rdNlOgWwDRnfU/RERkOmpdA2RpaYmbN2/Cz89P73haWhrMzWv3dlFRUZg3bx7WrVuH4OBgfPHFFwgJCUFiYiK8vLwqnB8REYGwsDBs2LABvXv3RmxsLGbMmAFHR0eMGTMGAPD999+jpKREd01WVha6deuGp59+ura3ahK0U+A5A4yIiEyJTKjlioUTJkxAeno6fvzxRzg4iL807969i9DQULRu3Ro7d+6s8XsFBQWhZ8+eiIiI0B3r1KkTQkNDsXz58grn9+/fH8HBwVi5cqXu2Lx583Dy5EkcOXKk0s9Ys2YN3nrrLaSlpcHGpvJdzouLi/W288jJyYGnpyeys7Nhb998C4M1GgHd3t2P3OJS7H15IDq7N997JSKi5i8nJwcODg41+v1d6yGw8PBwXL9+Hd7e3hgyZAiGDBkCX19fpKenIzw8vMbvU1JSgri4OAwbNkzv+LBhwxATE1PpNcXFxbCystI7plQqERsbC5VKVek1mzZtwoQJE6oMPwCwfPlyODg46B6enp41vg9jlny7ALnFpbAwN0N7FxZAExGR6ah1AGrTpg1Onz6NFStWoHPnzggMDMTHH3+MM2fO1Co4ZGZmQq1Ww8XFRe+4i4sL0tPTK71m+PDh2LhxI+Li4iAIAk6ePInIyEioVCpkZmZWOD82NhYJCQmYPn16tW0JCwtDdna27lFZkXdzpB3+6uRqBwULoImIyITUaSsMGxsbvPDCCwZpgEymv/WCIAgVjmktXrwY6enp6Nu3LwRBgIuLC6ZOnYoVK1ZALpdXOH/Tpk0ICAhAnz59qm2DpaUlLC0t634TRkq7AGIX1v8QEZGJqfNeYImJiUhOTtYrOAaAxx9/vEbXOzs7Qy6XV+jtycjIqNArpKVUKhEZGYkvvvgCN2/ehJubG9avXw87Ozs4OzvrnVtQUIAdO3ZgyZIltbgr05LAAmgiIjJRdVoJety4cThz5gxkMplu13dtr41ara7R+1hYWCAwMBDR0dEYN26c7nh0dDTGjh1b7bUKhQIeHh4AgB07dmD06NEwM9Mfwtm5cyeKi4sxadKkGt+bKREEAQkp3AOMiIhMU60LP+bOnQtfX1/cvHkT1tbWOHv2LP744w/06tULhw4dqtV7zZ8/Hxs3bkRkZCTOnTuHV155BcnJyZg5cyYAsTbnueee051//vx5bNu2DRcuXEBsbCwmTJiAhIQELFu2rMJ7b9q0CaGhoXBycqrtLZqEG3cKkV2ogkIuYwE0ERGZnFr3AB07dgwHDhxAq1atYGZmBjMzMwwYMADLly/Hyy+/jL///rvG7zV+/HhkZWVhyZIlSEtLQ0BAAPbu3avbaywtLQ3Jycm689VqNcLDw5GUlASFQoEhQ4YgJiYGPj4+eu97/vx5HDlyBPv376/t7ZkMbQG0v6sdLM0r1k8RERE1Z7UOQGq1Gra2Yo+Bs7MzUlNT4e/vD29vbyQlJdW6AS+99BJeeumlSl/bsmWL3vNOnTrVKGB16NABtVzeyORwAUQiIjJltQ5AAQEBOH36NPz8/BAUFIQVK1bAwsIC69evr7A6NDVd2gLoLtwCg4iITFCtA9CiRYuQn58PAFi6dClGjx6NgQMHwsnJCVFRUQZvIBmeWADNHiAiIjJdtQ5Aw4cP133t5+eHxMRE3L59G46OjlWu30NNS8rdQtwpUMHcTAZ/Vzupm0NERNToajULrLS0FObm5khISNA73rJlS4YfI6Kd/t7exQ5WChZAExGR6alVADI3N4e3t3eN1/qhpql8+IubnxIRkWmq9TpAixYtQlhYGG7fvt0Q7aFGwBlgRERk6mpdA/TJJ5/g4sWLcHd3h7e3d4Vd1v/66y+DNY4M794CaO4BRkREpqrWASg0NLQBmkGNJT2nCFn5JZCbydDZjUNgRERkmmodgN5+++2GaAc1kjM3xN6f9q1tWQBNREQmq9Y1QGTcElLFGWBcAJGIiExZrXuAzMzMqp3yzhliTRtngBEREdUhAO3evVvvuUqlwt9//42tW7fi3XffNVjDqGHoZoB5sAeIiIhMV60D0NixYysce+qpp9ClSxdERUXh+eefN0jDyPAycopwK7cYZjKgEwugiYjIhBmsBigoKAi//vqrod6OGoC296dtK1tYW9Q6+xIRETUbBglAhYWF+PTTT+Hh4WGIt6MGwgUQiYiIRLXuBrh/01NBEJCbmwtra2ts27bNoI0jw9LuAcYFEImIyNTVOgCtXr1aLwCZmZmhVatWCAoKgqOjo0EbR4aVwB4gIiIiAHUIQFOnTm2AZlBDu5VbjPScIshkQGd3FkATEZFpq3UN0ObNm/Htt99WOP7tt99i69atBmkUGV5Cqtj74+tsA1tLFkATEZFpq3UA+uCDD+Ds7FzheOvWrbFs2TKDNIoML+EGh7+IiIi0ah2Arl27Bl9f3wrHvb29kZycbJBGkeFxBhgREVG5Wgeg1q1b4/Tp0xWOnzp1Ck5OTgZpFBneWe4BRkREpFPrADRhwgS8/PLLOHjwINRqNdRqNQ4cOIC5c+diwoQJDdFGqqfb+SVIuVsIAOjCPcCIiIhqPwts6dKluHbtGoYOHQpzc/FyjUaD5557jjVATZR2+MvX2Qb2VgqJW0NERCS9WgcgCwsLREVFYenSpYiPj4dSqUTXrl3h7e3dEO0jA9Cu/9OF09+JiIgA1CEAabVv3x7t27c3ZFuogXABRCIiIn21rgF66qmn8MEHH1Q4vnLlSjz99NMGaRQZFmeAERER6at1APr9998xatSoCsdHjBiBP/74wyCNIsO5W1CCG3fKCqA5A4yIiAhAHQJQXl4eLCwsKhxXKBTIyckxSKPIcLQboHq1tIaDNQugiYiIgDoEoICAAERFRVU4vmPHDnTu3NkgjSLD4fAXERFRRbUugl68eDGefPJJXLp0CY888ggA4LfffsPXX3+N7777zuANpPrR7gHG9X+IiIjK1ToAPf744/jhhx+wbNkyfPfdd1AqlejWrRsOHDgAe3v+km1qOAOMiIioojpNgx81apSuEPru3bvYvn075s2bh1OnTkGtVhu0gVR32YUqXMsqAAAEsACaiIhIp9Y1QFoHDhzApEmT4O7ujs8++wwjR47EyZMnDdk2qqezZcNfbVoo4WhTsXCdiIjIVNWqB+jGjRvYsmULIiMjkZ+fj2eeeQYqlQq7du1iAXQTxOEvIiKiytW4B2jkyJHo3LkzEhMT8emnnyI1NRWffvppQ7aN6ulM2RT4rh4MQERERPeqcQ/Q/v378fLLL+PFF1/kFhhG4iz3ACMiIqpUjXuADh8+jNzcXPTq1QtBQUH47LPPcOvWrYZsG9VDbpEKlzPzAXAIjIiI6H41DkD9+vXDhg0bkJaWhv/85z/YsWMH2rRpA41Gg+joaOTm5jZkO6mWzqaKw1/uDlZwsrWUuDVERERNS61ngVlbW2PatGk4cuQIzpw5g1dffRUffPABWrdujccff7wh2kh1oC2A7sLeHyIiogrqPA0eAPz9/bFixQrcuHED33zzjaHaRAbAGWBERERVq1cA0pLL5QgNDcWePXsM8XZkANwDjIiIqGoGCUDUtOQXl+oKoLkHGBERUUUMQM1QYloOBAFwsbdEazsrqZtDRETU5DAANUNnbnD4i4iIqDoMQM1QQqp2AUQGICIiosowADVDnAFGRERUPQagZqagpBQXM/IAcA8wIiKiqjAANTPn0nKhEQBnW0u0tuMK0ERERJVhAGpmyoe/7CGTySRuDRERUdMkeQBat24dfH19YWVlhcDAQBw+fLja89euXYtOnTpBqVTC398fX375ZYVz7t69i1mzZsHNzQ1WVlbo1KkT9u7d21C30KRwAUQiIqIHM5fyw6OiojBv3jysW7cOwcHB+OKLLxASEoLExER4eXlVOD8iIgJhYWHYsGEDevfujdjYWMyYMQOOjo4YM2YMAKCkpASPPfYYWrduje+++w4eHh64fv067OzsGvv2JME9wIiIiB5MJgiCINWHBwUFoWfPnoiIiNAd69SpE0JDQ7F8+fIK5/fv3x/BwcFYuXKl7ti8efNw8uRJHDlyBADw+eefY+XKlfjnn3+gUCjq1K6cnBw4ODggOzsb9vbGs5JykUqNLm/vg1ojIGbBI3BvoZS6SURERI2mNr+/JRsCKykpQVxcHIYNG6Z3fNiwYYiJian0muLiYlhZ6a9srFQqERsbC5VKBQDYs2cP+vXrh1mzZsHFxQUBAQFYtmwZ1Gp1lW0pLi5GTk6O3sMYnUvLgVojwMnGAm4OXAGaiIioKpIFoMzMTKjVari4uOgdd3FxQXp6eqXXDB8+HBs3bkRcXBwEQcDJkycRGRkJlUqFzMxMAMDly5fx3XffQa1WY+/evVi0aBHCw8Px/vvvV9mW5cuXw8HBQffw9PQ03I02ooRUMbh1aePAAmgiIqJqSF4Eff8vakEQqvzlvXjxYoSEhKBv375QKBQYO3Yspk6dCkDckR4ANBoNWrdujfXr1yMwMBATJkzAwoUL9YbZ7hcWFobs7Gzd4/r164a5uUaWcKN8BhgRERFVTbIA5OzsDLlcXqG3JyMjo0KvkJZSqURkZCQKCgpw9epVJCcnw8fHB3Z2dnB2dgYAuLm5oUOHDrpABIh1Renp6SgpKan0fS0tLWFvb6/3MEacAUZERFQzkgUgCwsLBAYGIjo6Wu94dHQ0+vfvX+21CoUCHh4ekMvl2LFjB0aPHg0zM/FWgoODcfHiRWg0Gt3558+fh5ubGywsLAx/I01Ecaka52/mAuAeYERERA8i6RDY/PnzsXHjRkRGRuLcuXN45ZVXkJycjJkzZwIQh6aee+453fnnz5/Htm3bcOHCBcTGxmLChAlISEjAsmXLdOe8+OKLyMrKwty5c3H+/Hn8/PPPWLZsGWbNmtXo99eYktJzUaoR0MJaAQ9Hzv4iIiKqjqTrAI0fPx5ZWVlYsmQJ0tLSEBAQgL1798Lb2xsAkJaWhuTkZN35arUa4eHhSEpKgkKhwJAhQxATEwMfHx/dOZ6enti/fz9eeeUVPPTQQ2jTpg3mzp2LN998s7Fvr1HdO/zFAmgiIqLqSboOUFNljOsAhX1/Bt/EJmPmw22xIKSj1M0hIiJqdEaxDhAZVgILoImIiGqMAagZKCnVICldLIBmACIiInowBqBm4PzNXJSoNbC3ModnSxZAExERPQgDUDOgHf4KYAE0ERFRjTAANQNcAJGIiKh2GICagXv3ACMiIqIHYwAyciq1BufSxADEHiAiIqKaYQAychcz8lBSqoGdpTm8W1pL3RwiIiKjwABk5LT1P53d7WFmxgJoIiKimmAAMnJcAJGIiKj2GICMnC4AeTAAERER1RQDkBErVWuQWFYA3cWdAYiIiKimGICM2KVb+ShSaWBjIYefs43UzSEiIjIaDEBGTDv81cXdgQXQREREtcAAZMS0M8C6tLGXuCVERETGhQHIiHEGGBERUd0wABkptUbQFUAzABEREdUOA5CRupKZh4ISNZQKOfxa2UrdHCIiIqPCAGSk7l0BWs4CaCIiolphADJSCSkc/iIiIqorBiAjpZsB5s4ZYERERLXFAGSENBoBiallPUDcAoOIiKjWGICM0NWsfOQVl8LS3AztWABNRERUawxARkg7/NXJzR7mcv4IiYiIaou/PY0QF0AkIiKqHwYgI6SdARbALTCIiIjqhAHIyAiCgIRUsQcogD1AREREdcIAZGSuZRUgt6gUFnIzdHCxk7o5RERERokByMhoe386utlBwQJoIiKiOuFvUCOjnQHG4S8iIqK6YwAyMpwBRkREVH8MQEZEEITyGWDuDEBERER1xQBkRG7cKUR2oQoKuQwdXLkCNBERUV0xABkRbf2Pv6sdLM3lEreGiIjIeDEAGRFt/Q+Hv4iIiOqHAciIcAYYERGRYTAAGQmxAJozwIiIiAyBAchIpGYX4U6BCuZmMvi7cgVoIiKi+mAAMhJnboi9P+1d7GClYAE0ERFRfTAAGYny4S/uAE9ERFRfDEBGgjvAExERGQ4DkBG4twCaAYiIiKj+GICMQHpOETLzSiA3k6GzG4fAiIiI6osByAho9/9q18qWBdBEREQGwABkBLgAIhERkWExABkBzgAjIiIyLAYgI8ACaCIiIsNiAGriMnKKkJFbDDMZ0NmdPUBERESGwADUxGnrf9q2soW1hbnErSEiImoeGICaOO0MMA5/ERERGQ4DUBPHGWBERESGJ3kAWrduHXx9fWFlZYXAwEAcPny42vPXrl2LTp06QalUwt/fH19++aXe61u2bIFMJqvwKCoqasjbaDDlM8AYgIiIiAxF0qKSqKgozJs3D+vWrUNwcDC++OILhISEIDExEV5eXhXOj4iIQFhYGDZs2IDevXsjNjYWM2bMgKOjI8aMGaM7z97eHklJSXrXWllZNfj9GNqt3GKk5xRBxgJoIiIig5I0AK1atQrPP/88pk+fDgBYs2YN9u3bh4iICCxfvrzC+V999RX+85//YPz48QAAPz8/HD9+HB9++KFeAJLJZHB1dW2cm2hA2g1QfZ1tYGvJAmgiIiJDkWwIrKSkBHFxcRg2bJje8WHDhiEmJqbSa4qLiyv05CiVSsTGxkKlUumO5eXlwdvbGx4eHhg9ejT+/vvvattSXFyMnJwcvUdTkHCDw19EREQNQbIAlJmZCbVaDRcXF73jLi4uSE9Pr/Sa4cOHY+PGjYiLi4MgCDh58iQiIyOhUqmQmZkJAOjYsSO2bNmCPXv24JtvvoGVlRWCg4Nx4cKFKtuyfPlyODg46B6enp6Gu9F60PYABbgzABERERmS5EXQMplM77kgCBWOaS1evBghISHo27cvFAoFxo4di6lTpwIA5HJxk9C+ffti0qRJ6NatGwYOHIidO3eiQ4cO+PTTT6tsQ1hYGLKzs3WP69evG+bm6olT4ImIiBqGZAHI2dkZcrm8Qm9PRkZGhV4hLaVSicjISBQUFODq1atITk6Gj48P7Ozs4OzsXOk1ZmZm6N27d7U9QJaWlrC3t9d7SO12fglS7hYCALpwDzAiIiKDkiwAWVhYIDAwENHR0XrHo6Oj0b9//2qvVSgU8PDwgFwux44dOzB69GiYmVV+K4IgID4+Hm5ubgZre2PQTn/3cbKGvZVC4tYQERE1L5JOLZo/fz4mT56MXr16oV+/fli/fj2Sk5Mxc+ZMAOLQVEpKim6tn/PnzyM2NhZBQUG4c+cOVq1ahYSEBGzdulX3nu+++y769u2L9u3bIycnB5988gni4+Oxdu1aSe6xrrgAIhERUcORNACNHz8eWVlZWLJkCdLS0hAQEIC9e/fC29sbAJCWlobk5GTd+Wq1GuHh4UhKSoJCocCQIUMQExMDHx8f3Tl3797FCy+8gPT0dDg4OKBHjx74448/0KdPn8a+vXrhAohEREQNRyYIgiB1I5qanJwcODg4IDs7W7J6oIErDuD67UJsnx6E4HaV1zcRERFRudr8/pZ8FhhVdLegBNdviwXQnAJPRERkeAxATZB2+rtXS2s4WLMAmoiIyNAYgJog3QKInP5ORETUIBiAmiDOACMiImpYDEBNEGeAERERNSwGoCYmu1CFa1kFAFgATURE1FAYgJqYs2X1P21aKOFoYyFxa4iIiJonBqAmhsNfREREDY8BqIkp3wGeM8CIiIgaCgNQE5PAGWBEREQNjgGoCcktUuFyZj4ABiAiIqKGxADUhCSmisNfbg5WcLa1lLg1REREzRcDUBPCBRCJiIgaBwNQE8IZYERERI2DAagJSUjlDDAiIqLGYC51A0iUX1yKS7fyAHAIjIjqR6PRoKSkROpmEDUICwsLmJnVv/+GAaiJSEzLgSAALvaWaG1nJXVziMhIlZSU4MqVK9BoNFI3hahBmJmZwdfXFxYW9dstgQGoidCt/8P9v4iojgRBQFpaGuRyOTw9PQ3yr2SipkSj0SA1NRVpaWnw8vKCTCar83sxADURnAFGRPVVWlqKgoICuLu7w9raWurmEDWIVq1aITU1FaWlpVAoFHV+H/7zoIngDDAiqi+1Wg0A9R4aIGrKtH+/tX/f64oBqAkoLFHjYgYLoInIMOozLEDU1Bnq7zcDUBOQmJYDjQA421rCxZ4rQBMRETU0BqAmoHz4y57/ciMiMoDBgwdj3rx5NT7/6tWrkMlkiI+Pb7A2UdPCANQEcAd4IjJVMpms2sfUqVPr9L7ff/893nvvvRqf7+npibS0NAQEBNTp8+pi2LBhkMvlOH78eKN9JpXjLLAmgDPAiMhUpaWl6b6OiorCW2+9haSkJN0xpVKpd75KparRzJ+WLVvWqh1yuRyurq61uqY+kpOTcezYMcyePRubNm1C3759G+2zK1PT72tzwh4giRWp1LhQVgDNGWBEZEiCIKCgpFSShyAINWqjq6ur7uHg4ACZTKZ7XlRUhBYtWmDnzp0YPHgwrKyssG3bNmRlZeHZZ5+Fh4cHrK2t0bVrV3zzzTd673v/EJiPjw+WLVuGadOmwc7ODl5eXli/fr3u9fuHwA4dOgSZTIbffvsNvXr1grW1Nfr3768XzgBg6dKlaN26Nezs7DB9+nQsWLAA3bt3f+B9b968GaNHj8aLL76IqKgo5Ofn671+9+5dvPDCC3BxcYGVlRUCAgLw008/6V4/evQoHn74YVhbW8PR0RHDhw/HnTt3dPe6Zs0avffr3r073nnnHd1zmUyGzz//HGPHjoWNjQ2WLl0KtVqN559/Hr6+vlAqlfD398fHH39coe2RkZHo0qULLC0t4ebmhtmzZwMApk2bhtGjR+udW1paCldXV0RGRj7we9LY2AMksX/Sc6HWCGhpYwE3B64ATUSGU6hSo/Nb+yT57MQlw2FtYZhfMW+++SbCw8OxefNmWFpaoqioCIGBgXjzzTdhb2+Pn3/+GZMnT4afnx+CgoKqfJ/w8HC89957+O9//4vvvvsOL774IgYNGoSOHTtWec3ChQsRHh6OVq1aYebMmZg2bRqOHj0KANi+fTvef/99rFu3DsHBwdixYwfCw8Ph6+tb7f0IgoDNmzdj7dq16NixIzp06ICdO3fi3//+NwBxsb+QkBDk5uZi27ZtaNu2LRITEyGXywEA8fHxGDp0KKZNm4ZPPvkE5ubmOHjwYK2nhb/99ttYvnw5Vq9eDblcDo1GAw8PD+zcuRPOzs6IiYnBCy+8ADc3NzzzzDMAgIiICMyfPx8ffPABQkJCkJ2drft+TJ8+HYMGDUJaWhrc3NwAAHv37kVeXp7u+qaEAUhi9w5/sQCaiKiiefPm4YknntA79tprr+m+njNnDn755Rd8++231QagkSNH4qWXXgIghqrVq1fj0KFD1Qag999/Hw8//DAAYMGCBRg1ahSKiopgZWWFTz/9FM8//7wuuLz11lvYv38/8vLyqr2fX3/9FQUFBRg+fDgAYNKkSdi0aZPufX799VfExsbi3Llz6NChAwDAz89Pd/2KFSvQq1cvrFu3TnesS5cu1X5mZf71r39h2rRpesfeffdd3de+vr6IiYnBzp07dQFm6dKlePXVVzF37lzdeb179wYA9O/fH/7+/vjqq6/wxhtvABB7up5++mnY2trWun0NjQFIYgk3ymeAEREZklIhR+KS4ZJ9tqH06tVL77larcYHH3yAqKgopKSkoLi4GMXFxbCxsan2fR566CHd19qhtoyMjBpfo+3VyMjIgJeXF5KSknSBSqtPnz44cOBAte+5adMmjB8/Hubm4q/gZ599Fq+//jqSkpLg7++P+Ph4eHh46MLP/eLj4/H0009X+xk1cf/3FQA+//xzbNy4EdeuXUNhYSFKSkp0Q3oZGRlITU3F0KFDq3zP6dOnY/369XjjjTeQkZGBn3/+Gb/99lu929oQGIAklpDKPcCIqGHIZDKDDUNJ6f5gEx4ejtWrV2PNmjXo2rUrbGxsMG/ePJSUlFT7PvcX+cpksgduGnvvNdpe+nuvub/n/kG1T7dv38YPP/wAlUqFiIgI3XG1Wo3IyEh8+OGHFQq/7/eg183MzCq0Q6VSVTjv/u/rzp078corryA8PBz9+vWDnZ0dVq5ciRMnTtTocwHgueeew4IFC3Ds2DEcO3YMPj4+GDhw4AOvkwKLoCVUXKrG+Zu5ADgDjIiopg4fPoyxY8di0qRJ6NatG/z8/HDhwoVGb4e/vz9iY2P1jp08ebLaa7Zv3w4PDw+cOnUK8fHxuseaNWuwdetWlJaW4qGHHsKNGzdw/vz5St/joYceqrZXpVWrVnqz63JycnDlypUH3s/hw4fRv39/vPTSS+jRowfatWuHS5cu6V63s7ODj49PtZ/t5OSE0NBQbN68GZs3b9YN6zVFxv9PAyOWlJ4LlVpAC2sFPBwfnKyJiAho164ddu3ahZiYGDg6OmLVqlVIT09Hp06dGrUdc+bMwYwZM9CrVy/0798fUVFROH36tF69zv02bdqEp556qsJ6Q97e3njzzTfx888/Y+zYsRg0aBCefPJJrFq1Cu3atcM///wDmUyGESNGICwsDF27dsVLL72EmTNnwsLCAgcPHsTTTz8NZ2dnPPLII9iyZQvGjBkDR0dHLF68WFdAXZ127drhyy+/xL59++Dr64uvvvoKf/75p15R9zvvvIOZM2eidevWukLto0ePYs6cObpzpk+fjtGjR0OtVmPKlCl1+M42DvYASSghJQeAOPzFAmgioppZvHgxevbsieHDh2Pw4MFwdXVFaGhoo7dj4sSJCAsLw2uvvYaePXviypUrmDp1KqysKp/RGxcXh1OnTuHJJ5+s8JqdnR2GDRuGTZs2AQB27dqF3r1749lnn0Xnzp3xxhtv6GZ5dejQAfv378epU6fQp08f9OvXDz/++KOupigsLAyDBg3C6NGjMXLkSISGhqJt27YPvJ+ZM2fiiSeewPjx4xEUFISsrKwKNU5TpkzBmjVrsG7dOnTp0gWjR4+u0Pv26KOPws3NDcOHD4e7u/uDv5ESkQk1XazBhOTk5MDBwQHZ2dmwt2+44uSw78/gm9hkzHy4LRaEVD0LgYioJoqKinDlyhX4+vpW+UuYGtZjjz0GV1dXfPXVV1I3RTIFBQVwd3dHZGRkhdl7hlDd3/Pa/P7mEJiEyvcAY/0PEZGxKSgowOeff47hw4dDLpfjm2++wa+//oro6GipmyYJjUaD9PR0hIeHw8HBAY8//rjUTaoWA5BESko1SErXFkBzCjwRkbGRyWTYu3cvli5diuLiYvj7+2PXrl149NFHpW6aJJKTk+Hr6wsPDw9s2bJFNyTXVDXt1jVj52/mokStgb2VObxaWkvdHCIiqiWlUolff/1V6mY0GT4+PjXeAqUpYBG0RBK4AjQREZFkGIAkolsAkfU/REREjY4BSCJntFPgGYCIiIgaHQOQBFRqDc6liQGIM8CIiIgaHwOQBC5m5KGkVANbS3N4swCaiIio0TEASeBMWQF0F3d7mJmxAJqIiKixMQBJgAsgEhEZ1uDBgzFv3jzdcx8fH6xZs6baa2QyGX744Yd6f7ah3ocaFwOQBO6dAk9EZMrGjBlT5cKBx44dg0wmw19//VXr9/3zzz/xwgsv1Ld5et555x107969wvG0tDSEhIQY9LOqUlhYCEdHR7Rs2RKFhYWN8pnNFQNQIytVa5CYxhlgREQA8Pzzz+PAgQO4du1ahdciIyPRvXt39OzZs9bv26pVK1hbN06NpaurKywtLRvls3bt2oWAgAB07twZ33//faN8ZlUEQUBpaamkbagPBqBGdulWPopUGthYyOHnbCN1c4ioORMEoCRfmkcNVwQePXo0WrdujS1btugdLygoQFRUFJ5//nlkZWXh2WefhYeHB6ytrdG1a1d888031b7v/UNgFy5cwKBBg2BlZYXOnTtXul/Xm2++iQ4dOsDa2hp+fn5YvHgxVCoVAGDLli149913cerUKchkMshkMl2b7x8CO3PmDB555BEolUo4OTnhhRdeQF5enu71qVOnIjQ0FB999BHc3Nzg5OSEWbNm6T6rOps2bcKkSZMwadIk3c7x9zp79ixGjRoFe3t72NnZYeDAgbh06ZLu9cjISHTp0gWWlpZwc3PD7NmzAQBXr16FTCZDfHy87ty7d+9CJpPh0KFDAIBDhw5BJpNh37596NWrFywtLXH48GFcunQJY8eOhYuLC2xtbdG7d+8KK2QXFxfjjTfegKenJywtLdG+fXts2rQJgiCgXbt2+Oijj/TOT0hIgJmZmV7bDY1bYTQy7fBXZxZAE1FDUxUAy9yl+ez/pgIWD/5Hnrm5OZ577jls2bIFb731lm5l/G+//RYlJSWYOHEiCgoKEBgYiDfffBP29vb4+eefMXnyZPj5+SEoKOiBn6HRaPDEE0/A2dkZx48fR05Ojl69kJadnR22bNkCd3d3nDlzBjNmzICdnR3eeOMNjB8/HgkJCfjll190v9wdHCr24hcUFGDEiBHo27cv/vzzT2RkZGD69OmYPXu2Xsg7ePAg3NzccPDgQVy8eBHjx49H9+7dMWPGjCrv49KlSzh27Bi+//57CIKAefPm4fLly/Dz8wMApKSkYNCgQRg8eDAOHDgAe3t7HD16VNdLExERgfnz5+ODDz5ASEgIsrOzcfTo0Qd+/+73xhtv4KOPPoKfnx9atGiBGzduYOTIkVi6dCmsrKywdetWjBkzBklJSfDy8gIAPPfcczh27Bg++eQTdOvWDVeuXEFmZiZkMhmmTZuGzZs347XXXtN9RmRkJAYOHIi2bdvWun01xQDUyM6w/oeISM+0adOwcuVKHDp0CEOGDAEg/gJ84okn4OjoCEdHR71fjnPmzMEvv/yCb7/9tkYB6Ndff8W5c+dw9epVeHh4AACWLVtWoW5n0aJFuq99fHzw6quvIioqCm+88QaUSiVsbW1hbm4OV1fXKj9r+/btKCwsxJdffgkbGzEAfvbZZxgzZgw+/PBDuLi4AAAcHR3x2WefQS6Xo2PHjhg1ahR+++23agNQZGQkQkJC4OjoCAAYMWIEIiMjsXTpUgDA2rVr4eDggB07dkChUAAAOnTooLt+6dKlePXVVzF37lzdsd69ez/w+3e/JUuW4LHHHtM9d3JyQrdu3fQ+Z/fu3dizZw9mz56N8+fPY+fOnYiOjtbVe2lDGwD8+9//xltvvYXY2Fj06dMHKpUK27Ztw8qVK2vdttpgAGpknAFGRI1GYS32xEj12TXUsWNH9O/fH5GRkRgyZAguXbqEw4cPY//+/QAAtVqNDz74AFFRUUhJSUFxcTGKi4t1AeNBzp07By8vL134AYB+/fpVOO+7777DmjVrcPHiReTl5aG0tBT29vY1vg/tZ3Xr1k2vbcHBwdBoNEhKStIFoC5dukAul+vOcXNzw5kzZ6p8X7Vaja1bt+Ljjz/WHZs0aRJeeeUVvPvuu5DL5YiPj8fAgQN14edeGRkZSE1NxdChQ2t1P5Xp1auX3vP8/Hy8++67+Omnn5CamorS0lIUFhYiOTkZABAfHw+5XI6HH3640vdzc3PDqFGjEBkZiT59+uCnn35CUVERnn766Xq3tTqsAWpEao3AAmgiajwymTgMJcWjlps8P//889i1axdycnKwefNmeHt7635Zh4eHY/Xq1XjjjTdw4MABxMfHY/jw4SgpKanRe1e2Q/n9m1AfP34cEyZMQEhICH766Sf8/fffWLhwYY0/497PqmqD63uP3x9SZDIZNBpNle+7b98+pKSkYPz48TA3N4e5uTkmTJiAGzdu6IKiUqms8vrqXgMAMzMzXfu1qqpJuj94vv7669i1axfef/99HD58GPHx8ejatavue/egzwaA6dOnY8eOHSgsLMTmzZsxfvz4Bi9ilzwArVu3Dr6+vrCyskJgYCAOHz5c7flr165Fp06doFQq4e/vjy+//LLKc3fs2AGZTIbQ0FADt7purmTmoaBEDaVCjratbKVuDhFRk/HMM89ALpfj66+/xtatW/Hvf/9bFxgOHz6MsWPHYtKkSejWrRv8/Pxw4cKFGr93586dkZycjNTU8t6wY8eO6Z1z9OhReHt7Y+HChejVqxfat29fYWaahYUF1Gr1Az8rPj4e+fn5eu9tZmamNxxVW5s2bcKECRMQHx+v95g4caKuGPqhhx7C4cOHKw0udnZ28PHxwW+//Vbp+7dq1QqAOKVf696C6OocPnwYU6dOxbhx49C1a1e4urri6tWrute7du0KjUaD33//vcr3GDlyJGxsbBAREYH//e9/mDZtWo0+uz4kDUBRUVGYN28eFi5ciL///hsDBw5ESEiIrtvsfhEREQgLC8M777yDs2fP4t1338WsWbPwf//3fxXOvXbtGl577TUMHDiwoW+jxm7mFMPRWoHO7vaQswCaiEjH1tYW48ePx3//+1+kpqZi6tSputfatWuH6OhoxMTE4Ny5c/jPf/6D9PT0Gr/3o48+Cn9/fzz33HM4deoUDh8+jIULF+qd065dOyQnJ2PHjh24dOkSPvnkE+zevVvvHB8fH1y5cgXx8fHIzMxEcXFxhc+aOHEirKysMGXKFCQkJODgwYOYM2cOJk+erBv+qq1bt27h//7v/zBlyhQEBAToPaZMmYI9e/bg1q1bmD17NnJycjBhwgScPHkSFy5cwFdffYWkpCQA4jpG4eHh+OSTT3DhwgX89ddf+PTTTwGIvTR9+/bFBx98gMTERPzxxx96NVHVadeuHb7//nvEx8fj1KlT+Ne//qXXm+Xj44MpU6Zg2rRp+OGHH3DlyhUcOnQIO3fu1J0jl8sxdepUhIWFoV27dpUOURqcIKE+ffoIM2fO1DvWsWNHYcGCBZWe369fP+G1117TOzZ37lwhODhY71hpaakQHBwsbNy4UZgyZYowduzYWrUrOztbACBkZ2fX6rqa0Gg0Qk5hicHfl4iosLBQSExMFAoLC6VuSp3ExMQIAIRhw4bpHc/KyhLGjh0r2NraCq1btxYWLVokPPfcc3r/b3/44YeFuXPn6p57e3sLq1ev1j1PSkoSBgwYIFhYWAgdOnQQfvnlFwGAsHv3bt05r7/+uuDk5CTY2toK48ePF1avXi04ODjoXi8qKhKefPJJoUWLFgIAYfPmzYIgCBXe5/Tp08KQIUMEKysroWXLlsKMGTOE3Nxc3euV/V6aO3eu8PDDD1f6ffnoo4+EFi1aCCUlFX93qFQqoWXLlkJ4eLggCIJw6tQpYdiwYYK1tbVgZ2cnDBw4ULh06ZLu/M8//1zw9/cXFAqF4ObmJsyZM0f3WmJiotC3b19BqVQK3bt3F/bv3y8AEA4ePCgIgiAcPHhQACDcuXNHrw1XrlwRhgwZIiiVSsHT01P47LPPKvw8CgsLhVdeeUVwc3MTLCwshHbt2gmRkZF673Pp0iUBgLBixYpKvw/3vldVf89r8/tbJgg1XKzBwEpKSmBtbY1vv/0W48aN0x2fO3cu4uPjK+0qCwwMxMiRI/Hee+/pjoWFhSE8PBz5+fm6MdW3334bp0+fxu7duzF16lTcvXu32mXKtQV1Wjk5OfD09ER2dnatC+CIiKRSVFSEK1eu6MoKiIzJ0aNHMXjwYNy4caPa3rLq/p7n5OTAwcGhRr+/JRsCy8zMhFqtrnCTLi4uVXZtDh8+HBs3bkRcXBwEQcDJkycRGRkJlUqFzMxMAOI3cNOmTdiwYUON27J8+XI4ODjoHp6ennW/MSIiIqqx4uJiXLx4EYsXL8YzzzxT56HC2pK8CPr+anmhmgr6xYsXIyQkBH379oVCocDYsWN148RyuRy5ubmYNGkSNmzYAGdn5xq3ISwsDNnZ2brH9evX63w/REREVHPffPMN/P39kZ2djRUrVjTa50q2DpCzszPkcnmF3p6MjIwq059SqURkZCS++OIL3Lx5E25ubli/fj3s7Ozg7OyM06dP4+rVqxgzZozuGm0hlrm5OZKSkipdVdLS0rLR9nEhIiKiclOnTtUrem8skvUAWVhYIDAwsMJ+LNHR0ejfv3+11yoUCnh4eEAul2PHjh0YPXo0zMzM0LFjR5w5c0ZviuDjjz+OIUOGID4+nkNbREREBEDilaDnz5+PyZMno1evXujXrx/Wr1+P5ORkzJw5E4A4NJWSkqJb6+f8+fOIjY1FUFAQ7ty5g1WrViEhIQFbt24FAFhZWSEgIEDvM1q0aAEAFY4TETVXEs1tIWoUhvr7LWkAGj9+PLKysrBkyRKkpaUhICAAe/fuhbe3NwBxQaZ71wRSq9UIDw9HUlISFAoFhgwZgpiYGPj4+Eh0B0RETYd2a4WSkpIarb5LZIy0K0zfu5VIXUg2Db4pq800OiKipkIQBCQnJ0OlUsHd3V23vQFRc6HRaJCamgqFQgEvL68Kk6Zq8/ubm6ESETUTMpkMbm5uuHLlSoVtHIiaCzMzs0rDT20xABERNSMWFhZo3759rTfxJDIWFhYWBundZAAiImpmzMzMuBI00QNwgJiIiIhMDgMQERERmRwGICIiIjI5rAGqhHZlgJycHIlbQkRERDWl/b1dkxV+GIAqkZubCwDcOoOIiMgI5ebmwsHBodpzuBBiJbQLLdnZ2dV7nYH75eTkwNPTE9evX+cii00Afx5NC38eTQt/Hk0PfybVEwQBubm5NVoIlD1AlTAzM4OHh0eDfoa9vT3/8jYh/Hk0Lfx5NC38eTQ9/JlU7UE9P1osgiYiIiKTwwBEREREJocBqJFZWlri7bffhqWlpdRNIfDn0dTw59G08OfR9PBnYjgsgiYiIiKTwx4gIiIiMjkMQERERGRyGICIiIjI5DAAERERkclhAGpE69atg6+vL6ysrBAYGIjDhw9L3SSTtXz5cvTu3Rt2dnZo3bo1QkNDkZSUJHWzCOLPRiaTYd68eVI3xaSlpKRg0qRJcHJygrW1Nbp37464uDipm2WSSktLsWjRIvj6+kKpVMLPzw9LliyBRqORumlGjQGokURFRWHevHlYuHAh/v77bwwcOBAhISFITk6Wumkm6ffff8esWbNw/PhxREdHo7S0FMOGDUN+fr7UTTNpf/75J9avX4+HHnpI6qaYtDt37iA4OBgKhQL/+9//kJiYiPDwcLRo0ULqppmkDz/8EJ9//jk+++wznDt3DitWrMDKlSvx6aefSt00o8Zp8I0kKCgIPXv2REREhO5Yp06dEBoaiuXLl0vYMgKAW7duoXXr1vj9998xaNAgqZtjkvLy8tCzZ0+sW7cOS5cuRffu3bFmzRqpm2WSFixYgKNHj7KXuokYPXo0XFxcsGnTJt2xJ598EtbW1vjqq68kbJlxYw9QIygpKUFcXByGDRumd3zYsGGIiYmRqFV0r+zsbABAy5YtJW6J6Zo1axZGjRqFRx99VOqmmLw9e/agV69eePrpp9G6dWv06NEDGzZskLpZJmvAgAH47bffcP78eQDAqVOncOTIEYwcOVLilhk3bobaCDIzM6FWq+Hi4qJ33MXFBenp6RK1irQEQcD8+fMxYMAABAQESN0ck7Rjxw789ddf+PPPP6VuCgG4fPkyIiIiMH/+fPz3v/9FbGwsXn75ZVhaWuK5556Tunkm580330R2djY6duwIuVwOtVqN999/H88++6zUTTNqDECNSCaT6T0XBKHCMWp8s2fPxunTp3HkyBGpm2KSrl+/jrlz52L//v2wsrKSujkEQKPRoFevXli2bBkAoEePHjh79iwiIiIYgCQQFRWFbdu24euvv0aXLl0QHx+PefPmwd3dHVOmTJG6eUaLAagRODs7Qy6XV+jtycjIqNArRI1rzpw52LNnD/744w94eHhI3RyTFBcXh4yMDAQGBuqOqdVq/PHHH/jss89QXFwMuVwuYQtNj5ubGzp37qx3rFOnTti1a5dELTJtr7/+OhYsWIAJEyYAALp27Ypr165h+fLlDED1wBqgRmBhYYHAwEBER0frHY+Ojkb//v0lapVpEwQBs2fPxvfff48DBw7A19dX6iaZrKFDh+LMmTOIj4/XPXr16oWJEyciPj6e4UcCwcHBFZaFOH/+PLy9vSVqkWkrKCiAmZn+r2u5XM5p8PXEHqBGMn/+fEyePBm9evVCv379sH79eiQnJ2PmzJlSN80kzZo1C19//TV+/PFH2NnZ6XrnHBwcoFQqJW6dabGzs6tQe2VjYwMnJyfWZEnklVdeQf/+/bFs2TI888wziI2Nxfr167F+/Xqpm2aSxowZg/fffx9eXl7o0qUL/v77b6xatQrTpk2TumlGjdPgG9G6deuwYsUKpKWlISAgAKtXr+aUa4lUVXu1efNmTJ06tXEbQxUMHjyY0+Al9tNPPyEsLAwXLlyAr68v5s+fjxkzZkjdLJOUm5uLxYsXY/fu3cjIyIC7uzueffZZvPXWW7CwsJC6eUaLAYiIiIhMDmuAiIiIyOQwABEREZHJYQAiIiIik8MARERERCaHAYiIiIhMDgMQERERmRwGICIiIjI5DEBERERkchiAiIhqQCaT4YcffpC6GURkIAxARNTkTZ06FTKZrMJjxIgRUjeNiIwUN0MlIqMwYsQIbN68We+YpaWlRK0hImPHHiAiMgqWlpZwdXXVezg6OgIQh6ciIiIQEhICpVIJX19ffPvtt3rXnzlzBo888giUSiWcnJzwwgsvIC8vT++cyMhIdOnSBZaWlnBzc8Ps2bP1Xs/MzMS4ceNgbW2N9u3bY8+ePQ1700TUYBiAiKhZWLx4MZ588kmcOnUKkyZNwrPPPotz584BAAoKCjBixAg4Ojrizz//xLfffotff/1VL+BERERg1qxZeOGFF3DmzBns2bMH7dq10/uMd999F8888wxOnz6NkSNHYuLEibh9+3aj3icRGYhARNTETZkyRZDL5YKNjY3eY8mSJYIgCAIAYebMmXrXBAUFCS+++KIgCIKwfv16wdHRUcjLy9O9/vPPPwtmZmZCenq6IAiC4O7uLixcuLDKNgAQFi1apHuel5cnyGQy4X//+5/B7pOIGg9rgIjIKAwZMgQRERF6x1q2bKn7ul+/fnqv9evXD/Hx8QCAc+fOoVu3brCxsdG9HhwcDI1Gg6SkJMhkMqSmpmLo0KHVtuGhhx7SfW1jYwM7OztkZGTU9ZaISEIMQERkFGxsbCoMST2ITCYDAAiCoPu6snOUSmWN3k+hUFS4VqPR1KpNRNQ0sAaIiJqF48ePV3jesWNHAEDnzp0RHx+P/Px83etHjx6FmZkZOnToADs7O/j4+OC3335r1DYTkXTYA0RERqG4uBjp6el6x8zNzeHs7AwA+Pbbb9GrVy8MGDAA27dvR2xsLDZt2gQAmDhxIt5++21MmTIF77zzDm7duoU5c+Zg8uTJcHFxAQC88847mDlzJlq3bo2QkBDk5ubi6NGjmDNnTuPeKBE1CgYgIjIKv/zyC9zc3PSO+fv7459//gEgztDasWMHXnrpJbi6umL79u3o3LkzAMDa2hr79u3D3Llz0bt3b1hbW+PJJ5/EqlWrdO81ZcoUFBUVYfXq1Xjttdfg7OyMp556qvFukIgalUwQBEHqRhAR1YdMJsPu3bsRGhoqdVOIyEiwBoiIiIhMDgMQERERmRzWABGR0eNIPhHVFnuAiIiIyOQwABEREZHJYQAiIiIik8MARERERCaHAYiIiIhMDgMQERERmRwGICIiIjI5DEBERERkcv4fEjLayw/SGSAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Evaluate the model on test data\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print(\"Test Accuracy:\", test_acc)\n",
    "\n",
    "# Plot training and validation accuracy\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b77508-623e-460f-846a-718ccd374bd7",
   "metadata": {},
   "source": [
    "Analyzing AlexNet\n",
    "\n",
    " Ans 1) Here's an overview of the AlexNet architecture:\n",
    "\n",
    "Input Layer:\n",
    "\n",
    "AlexNet takes an input image of size 227x227x3 (RGB channels). The size of 227x227 was chosen to fit the original ImageNet images while retaining spatial information.\n",
    "Convolutional Layers:\n",
    "\n",
    "AlexNet consists of five convolutional layers, with each followed by a max-pooling layer. These convolutional layers are responsible for extracting hierarchical features from the input image.\n",
    "The convolutional layers use small receptive fields (typically 3x3) and a stride of 1, enabling them to capture local patterns effectively.\n",
    "The first convolutional layer uses a larger kernel size of 11x11 with a stride of 4 to capture a larger context.\n",
    "Activation Functions:\n",
    "\n",
    "Throughout the network, AlexNet uses the rectified linear unit (ReLU) activation function after each convolutional and fully connected layer. ReLU helps introduce non-linearity into the model and accelerates training by mitigating the vanishing gradient problem.\n",
    "Normalization and Regularization:\n",
    "\n",
    "AlexNet incorporates normalization and regularization techniques to improve generalization performance and prevent overfitting.\n",
    "Local Response Normalization (LRN) is applied after the first and second convolutional layers to enhance the contrast between the activated neurons and improve generalization.\n",
    "Dropout regularization is applied to the fully connected layers to randomly drop a fraction of neurons during training, reducing co-adaptation of neurons and improving generalization.\n",
    "Fully Connected Layers:\n",
    "\n",
    "Following the convolutional layers, AlexNet includes three fully connected layers with ReLU activation.\n",
    "The fully connected layers integrate the extracted features from convolutional layers and learn complex non-linear mappings between features and class labels.\n",
    "The final fully connected layer consists of 1000 neurons, corresponding to the 1000 classes in the ImageNet dataset.\n",
    "Output Layer:\n",
    "\n",
    "The output layer uses the softmax activation function to produce class probabilities. Each neuron in the output layer represents the probability of the input image belonging to a specific class.\n",
    "Training:\n",
    "\n",
    "AlexNet is trained using stochastic gradient descent (SGD) with momentum. It employs data augmentation techniques such as random cropping and horizontal flipping to increase the effective size of the training dataset and improve robustness.\n",
    "Performance:\n",
    "\n",
    "AlexNet achieved a top-5 error rate of 15.3% in the ILSVRC 2012 competition, significantly outperforming previous state-of-the-art methods. Its success demonstrated the effectiveness of deep learning for image classification tasks and paved the way for further advancements in the field.\n",
    "In summary, AlexNet's architecture combines deep convolutional layers with ReLU activation, normalization, and regularization techniques to learn hierarchical features from images and make accurate predictions. Its success marked a milestone in the development of deep learning and inspired the design of subsequent CNN architectures."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a2b8928-cf0c-4172-b4e5-02053203cac3",
   "metadata": {},
   "source": [
    "Ans 2) The vanishing gradient problem is a challenge that arises during backpropagation in neural networks, particularly in deep feedforward and recurrent neural networks. Let’s delve into its details:\n",
    "\n",
    "Cause:\n",
    "During backpropagation, gradients (derivatives) are computed with respect to the model’s parameters (weights).\n",
    "As we move backward through the layers, the gradients can become progressively smaller.\n",
    "This phenomenon occurs due to certain activation functions (e.g., sigmoid) that squash their input values into a limited range (e.g., between 0 and 1).\n",
    "When gradients become too small, weight updates in the initial layers become negligible.\n",
    "Consequences:\n",
    "The vanishing gradient problem hinders effective training because the model fails to learn meaningful features.\n",
    "In deep networks, gradients may vanish exponentially as we move backward, preventing weight adjustments.\n",
    "Without proper gradients, the model cannot update its weights optimally.\n",
    "Solutions:\n",
    "Several techniques mitigate this issue:\n",
    "ReLU Activation: Rectified Linear Units (ReLUs) replace sigmoid activations. ReLUs allow gradients to flow more freely during backpropagation.\n",
    "Weight Initialization: Properly initializing weights (e.g., using He initialization) helps prevent vanishing gradients.\n",
    "Batch Normalization: Normalizing activations within each batch stabilizes training and mitigates gradient issues.\n",
    "Skip Connections: Architectures like ResNet use skip connections to allow gradients to bypass certain layers.\n",
    "Long Short-Term Memory (LSTM): For recurrent networks, LSTMs maintain gradients over longer sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa98504c-d338-4695-8a05-ad2ed4e5f530",
   "metadata": {},
   "source": [
    "Ans 3 ) Convolutional Layers:\n",
    "AlexNet consists of five convolutional layers that learn hierarchical features from the input image.\n",
    "These layers use convolutional filters (also known as kernels) to extract local patterns and features.\n",
    "The activation function used in these layers is the Rectified Linear Unit (ReLU), which accelerates training by allowing faster convergence.\n",
    "Here’s a summary of the convolutional layers:\n",
    "First Convolution Layer: Applies 96 filters of size 11x11 with a stride of 4. The resulting feature map is 55x55x96.\n",
    "Second Convolution Layer: Employs 256 filters of size 5x5 with a stride of 1 and padding of 2. The output size remains 27x27x256.\n",
    "Third Convolution Layer: Utilizes 384 filters of size 3x3 with a stride of 1 and padding of 1. The output feature map remains 13x13x384.\n",
    "Fourth Convolution Layer: Similar to the third layer, it also has 384 filters of size 3x3.\n",
    "Fifth Convolution Layer: Uses 256 filters of size 3x3.\n",
    "Max-Pooling Layers:\n",
    "AlexNet employs three max-pooling layers to downsample the feature maps.\n",
    "Each max-pooling layer reduces the spatial dimensions while preserving important features.\n",
    "The resulting feature map sizes after max-pooling are 27x27x96, 13x13x256, and 13x13x384.\n",
    "Fully Connected Layers:\n",
    "After the convolutional and pooling layers, AlexNet has two fully connected layers.\n",
    "These layers learn complex combinations of features and contribute to the final classification.\n",
    "The output of the last fully connected layer feeds into the softmax classifier.\n",
    "Softmax Classifier:\n",
    "The final layer computes class probabilities based on the learned features.\n",
    "It assigns the most likely class label to the input image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8763ff29-5230-4646-a91c-3392d9953d62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
